{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15945d26",
   "metadata": {},
   "source": [
    "# Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b6eab989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pprint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchsummary import summary\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import tqdm.notebook as tq\n",
    "import utils\n",
    "from tkinter import Tcl # file sorting by name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be7763c",
   "metadata": {},
   "source": [
    "# Creation of labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed8ded2",
   "metadata": {},
   "source": [
    "### Dictionary creation for the classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70c4013",
   "metadata": {},
   "source": [
    "We want a dictionary indicating a numbeer for each genre:\n",
    "\n",
    "{0: 'Hip-Hop', 1: 'Pop', 2: 'Folk', 3: 'Rock', 4: 'Experimental', 5: 'International', 6: 'Electronic', 7: 'Instrumental'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029e985c",
   "metadata": {},
   "source": [
    "### Creation of the labels vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be9951a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_folder: data/fma_small_stft_transposed/train\n",
      "validation_folder: data/fma_small_stft_transposed/validation\n",
      "test_folder: data/fma_small_stft_transposed/test \n",
      "\n",
      "audio directory:  ./data/fma_small/\n",
      "Loading tracks.csv...\n",
      "small dataset shape: (8000, 52)\n",
      "Track.csv: 6400 training samples, 800 validation samples, 800 test samples\n",
      "\n",
      "there are 8 unique genres\n",
      "Dictionary of genres created: {'Hip-Hop': 0, 'Pop': 1, 'Folk': 2, 'Rock': 3, 'Experimental': 4, 'International': 5, 'Electronic': 6, 'Instrumental': 7}\n",
      "labels length: 63970\n",
      "labels length: 8000\n",
      "labels length: 8000\n"
     ]
    }
   ],
   "source": [
    "def create_single_dataset(folder_path, tracks_dataframe, genre_dictionary):    \n",
    "    labels = []\n",
    "   \n",
    "    _, file_list = get_sorted_file_paths(folder_path)\n",
    "    \n",
    "    for i,file in enumerate(file_list):\n",
    "        #print(\"considering file:\",file, \"({}/{})\".format(i,len(file_list)))\n",
    "        track_id_clip_id = file.split('.')[0]\n",
    "        track_id = track_id_clip_id.split('_')[0]\n",
    "        #print(\"track id with clip: {}, track id: {}\".format(track_id_clip_id, track_id))\n",
    "        genre = tracks_dataframe.loc[int(track_id)]\n",
    "        #print(\"genre from dataframe: \", genre)\n",
    "        label = genre_dictionary[genre]\n",
    "        #print(\"label from dictionary:\",label)\n",
    "        labels.append(label)\n",
    "    print(\"labels length: {}\".format(len(labels)))\n",
    "    return labels\n",
    "    \n",
    "\n",
    "#create the train,validation and test vectors using the files in the train/validation/test folders\n",
    "def create_dataset_splitted(folder_path):\n",
    "    train_folder = os.path.join(folder_path,'train') # concatenate train folder to path\n",
    "    validation_folder = os.path.join(folder_path,'validation') # concatenate train folder to path\n",
    "    test_folder = os.path.join(folder_path,'test') # concatenate train folder to path\n",
    "    \n",
    "    print(\"train_folder:\",train_folder)\n",
    "    print(\"validation_folder:\",validation_folder)\n",
    "    print(\"test_folder:\",test_folder,\"\\n\")\n",
    "    \n",
    "    AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "    print(\"audio directory: \",AUDIO_DIR)\n",
    "    print(\"Loading tracks.csv...\")\n",
    "    tracks = utils.load('data/fma_metadata/tracks.csv')\n",
    "    \n",
    "    #get only the small subset of the dataset\n",
    "    small = tracks[tracks['set', 'subset'] <= 'small']\n",
    "    print(\"small dataset shape:\",small.shape)    \n",
    "\n",
    "    small_training = small.loc[small[('set', 'split')] == 'training']['track']\n",
    "    small_validation = small.loc[small[('set', 'split')] == 'validation']['track']\n",
    "    small_test = small.loc[small[('set', 'split')] == 'test']['track']\n",
    "\n",
    "    print(\"Track.csv: {} training samples, {} validation samples, {} test samples\\n\".format(len(small_training), len(small_validation), len(small_test)))\n",
    "\n",
    "    small_training_top_genres = small_training['genre_top']\n",
    "    small_validation_top_genres = small_validation['genre_top']\n",
    "    small_test_top_genres = small_test['genre_top']\n",
    "    \n",
    "    #create dictionary of genre classes:\n",
    "    unique_genres = small_training_top_genres.unique()\n",
    "    unique_genres = np.array(unique_genres)\n",
    "    print(\"there are {} unique genres\".format(len(unique_genres)))\n",
    "    genre_dictionary = {}\n",
    "    for i,genre in enumerate(unique_genres):\n",
    "        genre_dictionary[genre] = i\n",
    "    print(\"Dictionary of genres created:\",genre_dictionary)\n",
    "    \n",
    "    \n",
    "    Y_train = create_single_dataset(train_folder, small_training_top_genres, genre_dictionary)\n",
    "    Y_validation = create_single_dataset(validation_folder, small_validation_top_genres, genre_dictionary)\n",
    "    Y_test = create_single_dataset(test_folder, small_test_top_genres, genre_dictionary)\n",
    "    \n",
    "    return Y_train, Y_validation, Y_test\n",
    " \n",
    "def get_sorted_file_paths(folder_path):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    #sort the dataset files in alphabetical order (important to associate correct labels created using track_id in track.csv)\n",
    "    file_list = Tcl().call('lsort', '-dict', file_list) # sort file by name: 2_0,2_1, ... 2_9,3_0, ... 400_0,400_1, ...\n",
    "    file_paths = [os.path.join(folder_path, file_name) for file_name in file_list] #join filename with folder path\n",
    "    #print(\"There are {} in the folder: {}\".format(len(file_list),file_list))\n",
    "    return file_paths, file_list\n",
    "    \n",
    "    \n",
    "folder_path=\"data/fma_small_stft_transposed\"\n",
    "Y_train, Y_validation, Y_test = create_dataset_splitted(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20175a8",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "187ddbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom class for accessing our dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_list, labels):\n",
    "        self.file_list = file_list\n",
    "        self.labels=labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # returns a training sample and its label\n",
    "        file_path = self.file_list[idx]\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "        stft_vector = torch.tensor(np.load(file_path)) #load from file\n",
    "        return stft_vector, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cae70891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of train dataset:  63970\n",
      "len of validation dataset:  8000\n",
      "len of test dataset:  8000\n"
     ]
    }
   ],
   "source": [
    "folder_path=\"data/fma_small_stft_transposed\"\n",
    "\n",
    "train_folder = os.path.join(folder_path,'train') # concatenate train folder to path\n",
    "validation_folder = os.path.join(folder_path,'validation') # concatenate train folder to path\n",
    "test_folder = os.path.join(folder_path,'test') # concatenate train folder to path\n",
    "\n",
    "train_file_paths, _ = get_sorted_file_paths(train_folder)\n",
    "train_dataset = MyDataset(train_file_paths, Y_train)\n",
    "print(\"len of train dataset: \",len(train_dataset))\n",
    "\n",
    "validation_file_paths, _ = get_sorted_file_paths(validation_folder)\n",
    "validation_dataset = MyDataset(validation_file_paths, Y_validation)\n",
    "print(\"len of validation dataset: \",len(validation_file_paths))\n",
    "\n",
    "test_file_paths, _ = get_sorted_file_paths(test_folder)\n",
    "test_dataset = MyDataset(test_file_paths, Y_test)\n",
    "print(\"len of test dataset: \",len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef67f394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_dimension_errors(filepaths):\n",
    "    error_indexes = []\n",
    "    progress = 0\n",
    "    for file in filepaths:\n",
    "        progress+=1\n",
    "        print(\"checked {}/{} files\".format(progress,len(filepaths)))\n",
    "        x = np.load(file)\n",
    "        if(x.shape != (128,513)):\n",
    "            error_indexes.append(x)\n",
    "            print(\"error\")\n",
    "    print(\"{} errors found in files: {}\".format(len(error_indexes),error_indexes))\n",
    "    for idx,error in enumerate(error_indexes):\n",
    "        print(\"index: {}, shape: {}\".format(idx,error.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a52dc",
   "metadata": {},
   "source": [
    "# Network Architecture Definition (nnet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "83f745b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNet1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=(4, 513), stride=(1,513))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        self.conv2 = nn.Conv2d(128, 128, kernel_size=(4, 1), stride=(1,513))\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=(4, 1), stride=(1,513))\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(26, 1))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(26, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout=nn.Dropout(0.3)\n",
    "        self.dense1 = nn.Linear(512, 300)\n",
    "        self.dense2 = nn.Linear(300, 150)\n",
    "        self.dense3 = nn.Linear(150, 8)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x_avg = self.avgpool(x)\n",
    "        x_max = self.maxpool(x)\n",
    "        x = torch.cat([x_avg, x_max], dim=1)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x=self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9845a53e",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d034d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=128\n",
    "EPOCHS=10\n",
    "LEARNING_RATE=0.0001\n",
    "\n",
    "learning_rate_list = [0.01, 0.001, 0.0001]\n",
    "batch_size_list = [128,256,512]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd576a3",
   "metadata": {},
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "223742e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, validation_dataset, Y_validation):\n",
    "    #Stop parameters learning\n",
    "    model.eval()\n",
    "    \n",
    "    validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=10)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    total_loss = 0\n",
    "    confusion_matrix = np.zeros((8,8 ), dtype=int)\n",
    "\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in validation_loader:\n",
    "            #print(\"Inputs:\",inputs,\"size:\",inputs.size())\n",
    "            #print(\"Labels:\",labels,\"size:\",labels.size())\n",
    "            inputs=inputs.unsqueeze(1)\n",
    "            #predict label\n",
    "            outputs = model(inputs)\n",
    "            #print(\"Outputs:\",outputs,\"size:\",outputs.size())\n",
    "            #compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            voting=outputs.mean(dim=0)\n",
    "            #print(\"Voting:\",voting,\"size:\",voting.size())\n",
    "           \n",
    "            predicted= torch.argmax(voting)\n",
    "            #print(\"winning class\",predicted)\n",
    "            correct += (predicted == labels[0])\n",
    "            confusion_matrix[predicted][labels[0]]+=1\n",
    "            \n",
    "    cm=ConfusionMatrixDisplay(confusion_matrix=confusion_matrix)\n",
    "    cm.plot()\n",
    "    print(confusion_matrix)\n",
    "    accuracy = 100*correct / 800 \n",
    "    average_loss = total_loss / 800\n",
    "    model.train()\n",
    "    return accuracy, average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0ca4e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataset, batch_size, num_epochs, learning_rate, verbose = False):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    val_loss_list=[]\n",
    "    val_acc_list=[]\n",
    "    train_loss_list=[]\n",
    "    train_acc_list=[]\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if not isinstance(dataset, Dataset):\n",
    "        raise ValueError(\"The dataset parameter should be an instance of torch.utils.data.Dataset.\")\n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    num_batches = len(data_loader)\n",
    "    \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0 \n",
    "        running_accuracy = 0.0\n",
    "        #initialize correctly predicted samples\n",
    "        \n",
    "        # Initialize the progress bar\n",
    "        progress_bar = tq.tqdm(total=num_batches, unit=\"batch\")\n",
    "    \n",
    "        # Initialize the progress bar description\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            \n",
    "            correct = 0 # reset train accuracy each batch\n",
    "            \n",
    "            inputs,labels = batch[0],batch[1]\n",
    "            if(verbose == True):\n",
    "                print(\"\\ninputs shape:\",inputs.size(),\", content: \",inputs)\n",
    "                print(\"\\nlabels shape:\",labels.size(),\", content: \",labels)\n",
    "            inputs = inputs.unsqueeze(1)\n",
    "            \n",
    "            # Extract the inputs and targets\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            if(verbose == True):\n",
    "                print(\"\\noutputs size:\",outputs.size(),\"content:\",outputs)\n",
    "\n",
    "            loss = criterion(outputs, labels) #labels need to be a vector of class indexes (0-7) of dim (batch_size)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            #calculate train accuracy\n",
    "            for index, output in enumerate(outputs):\n",
    "                max_index = torch.argmax(output).item() #the index with maximum probability\n",
    "                if(labels[index].item() == max_index):\n",
    "                    correct += 1\n",
    "            \n",
    "                if(verbose==True):\n",
    "                    print(\"considering output at index {}:\".format(index,output))\n",
    "                    print(\"max output index = {}\",max_index)\n",
    "                    if(labels[index].item() == max_index):\n",
    "                        print(\"correct! in fact labels[index] = {}, max_index = {}\".format(labels[index].item(),max_index))\n",
    "                    else:\n",
    "                        print(\"NOT correct! in fact labels[index] = {}, max_index = {}\".format(labels[index].item(),max_index))\n",
    "\n",
    "            \n",
    "            accuracy = 100 * correct / batch_size\n",
    "            running_accuracy += accuracy #epoch running_accuracy\n",
    "            \n",
    "            # Update the progress bar description and calculate bps\n",
    "            #progress_bar.set_postfix({\"Loss\": running_loss / (batch_idx + 1)})\n",
    "            average_accuracy = running_accuracy / (batch_idx + 1)\n",
    "            average_loss = running_loss / (batch_idx + 1)\n",
    "            progress_bar.set_postfix({\"avg_loss\": average_loss, \"acc\": accuracy, \"avg_acc\": average_accuracy})\n",
    "\n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "            # Evaluate the model on the validation dataset\n",
    "        \n",
    "        #calculate train loss and accuracy\n",
    "        average_loss = running_loss / len(data_loader)\n",
    "        average_accuracy = running_accuracy / len(data_loader)\n",
    "        train_loss_list.append(average_loss)\n",
    "        train_acc_list.append(average_accuracy)\n",
    "        \n",
    "        #calculate validation loss and accuracy\n",
    "        val_acc, val_loss = test(model, validation_dataset, Y_validation)\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        \n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}],Train Loss: {average_loss:.4f}. Train Accuracy: {average_accuracy} Val Loss: {val_loss} Val Accuracy: {val_acc}\")\n",
    "        progress_bar.close()\n",
    "    return train_loss_list, train_acc_list, val_loss_list, val_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbbc7adc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing model with batch size=128, lr=0.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7371cceaaa846cbb51fafe3b5b3149d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-e522e69697f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'model'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_lr_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m'_bs_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Traing model with batch size={bs}, lr={lr}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mperformance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mperformance_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperformance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmodel_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-0b7ef43db2fb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, batch_size, num_epochs, learning_rate, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# Extract the inputs and targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nndl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-205f6f8612f8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nndl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nndl/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nndl/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#summary(model, (1, 128, 513))\n",
    "performance_list = []\n",
    "model_list = []\n",
    "directory = 'models/'\n",
    "\n",
    "for lr in learning_rate_list:   \n",
    "    for bs in batch_size_list:\n",
    "        model = NNet1() #reinitialize model\n",
    "        file_path = directory + 'model' + '_lr_' + str(lr).split('.')[0] + '-' + str(lr).split('.')[1]+ '_bs_' + str(bs)\n",
    "        print(f\"Traing model with batch size={bs}, lr={lr}\")\n",
    "        performance=train(model, train_dataset, batch_size=bs, num_epochs=EPOCHS, learning_rate=lr)\n",
    "        performance_list.append(performance)\n",
    "        model_list.append(model)\n",
    "        print(\"saving model in\", file_path)\n",
    "        torch.save(model.state_dict(), file_path)\n",
    "        print(performance_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d928b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plt.plot(np.arange(1,EPOCHS+1), performance[1][:], label='Loss') \n",
    "plt.plot(np.arange(1,EPOCHS+1), performance[0][:], label='Accuracy')\n",
    "plt.legend()  # Display the legend showing the labels\n",
    "plt.show()\n",
    "print(performance[0][:])\n",
    "'''\n",
    "\n",
    "parameter_list = []\n",
    "for lr in learning_rate_list:\n",
    "    for bs in batch_size_list:\n",
    "        parameter_list.append([lr,bs])\n",
    "\n",
    "for performance, parameters in zip(performance_list, parameter_list):\n",
    "    plt.plot(np.arange(1,EPOCHS+1), performance[1][:], label='Val Loss') \n",
    "    plt.plot(np.arange(1,EPOCHS+1), performance[0][:], label='Val Accuracy')\n",
    "    plt.title(f\"Lr = {parameters[0]}, Batch size = {parameters[1]}\")\n",
    "    plt.legend()  # Display the legend showing the labels\n",
    "    plt.show()\n",
    "    print(performance[0][:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9ef7fab",
   "metadata": {},
   "source": [
    "# Network Architecture Definition (nnet1 + BN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b3685ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet1_BN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNet1_BN, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, 128, kernel_size=(4, 513), stride=(1, 513))\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        self.conv2 = nn.Conv2d(128, 128, kernel_size=(4, 1), stride=(1, 513))\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(2, 1))\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=(4, 1), stride=(1, 513))\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(26, 1))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(26, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.dense1 = nn.Linear(512, 300)\n",
    "        self.bn4 = nn.BatchNorm1d(300)\n",
    "        self.dense2 = nn.Linear(300, 150)\n",
    "        self.bn5 = nn.BatchNorm1d(150)\n",
    "        self.dense3 = nn.Linear(150, 8)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.dropout(x)\n",
    "        x_avg = self.avgpool(x)\n",
    "        x_max = self.maxpool(x)\n",
    "        x = torch.cat([x_avg, x_max], dim=1)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense1(x)\n",
    "        x = self.bn4(x)\n",
    "        \n",
    "        x = self.relu(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dense3(x)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61b169d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9f3484c0ad4b02b4d0ab42ff38dd7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[41 10  4  0  2  5  6  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 2 10 52  4 13  6  1 18]\n",
      " [ 0 21  7 81 12  6  2 16]\n",
      " [ 0  1  0  1 31  7  2  2]\n",
      " [ 8 17  5  6  8 47  6 16]\n",
      " [49 28  4  5 12 15 69 11]\n",
      " [ 0 13 28  3 22 14 14 37]]\n",
      "Epoch [1/10],Train Loss: 1.8884. Train Accuracy: 40.803125 Val Loss: 1.8640734665095806 Val Accuracy: 44.75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858ad86e54cb42308fcea606ee0c54a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[69 18  0  1  3  4 18  1]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 2 18 79  6 12  8  2 22]\n",
      " [ 1 17  5 76 10  4  1 16]\n",
      " [ 0 15  0  5 50 11  7 28]\n",
      " [ 6  9  5  4  4 61  6  4]\n",
      " [21 15  0  5  8  7 53  5]\n",
      " [ 1  8 11  3 13  5 13 24]]\n",
      "Epoch [2/10],Train Loss: 1.7782. Train Accuracy: 50.6328125 Val Loss: 1.799180273115635 Val Accuracy: 51.5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a98f1f51a2f4cf3a0a5c955e5474285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66  9  0  1  1  1  9  0]\n",
      " [ 0  0  0  0  0  0  0  0]\n",
      " [ 2 13 64  2  3  5  2  8]\n",
      " [ 1 14  7 73  7  1  2 16]\n",
      " [ 2 28  3 14 64 19 12 36]\n",
      " [ 8 13  6  6  3 65  9  5]\n",
      " [21 15  0  2  3  3 54  4]\n",
      " [ 0  8 20  2 19  6 12 31]]\n",
      "Epoch [3/10],Train Loss: 1.7353. Train Accuracy: 54.3296875 Val Loss: 1.802379274368286 Val Accuracy: 52.125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5055353ffb1e4e5c9629c62872bc26a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-0d7e92603c83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_NNet1_BN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNNet1_BN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_NNet1_BN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-0b7ef43db2fb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, batch_size, num_epochs, learning_rate, verbose)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m#calculate validation loss and accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mval_loss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mval_acc_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-65-d6457c5ef5be>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, validation_dataset, Y_validation)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0;31m#predict label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0;31m#print(\"Outputs:\",outputs,\"size:\",outputs.size())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;31m#compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nndl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-46-369ca05348ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nndl/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nndl/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nndl/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_NNet1_BN = NNet1_BN()\n",
    "\n",
    "train_loss_list, train_acc_list, val_loss_list, val_acc_list =train(model_NNet1_BN, train_dataset, batch_size=128, num_epochs=10, learning_rate=0.0001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc08332",
   "metadata": {},
   "source": [
    "# Network Architecture Definition (nnet2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fd36488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MusicGenreNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MusicGenreNet, self).__init__()\n",
    "        \n",
    "        # STFT spectrogram input: (batch_size, 1, 128, 513)\n",
    "        self.conv1 = nn.Conv2d(1, 256, kernel_size=(4, 513))\n",
    "        self.conv2 = nn.Conv2d(256, 256, kernel_size=(4, 1))\n",
    "        self.conv3 = nn.Conv2d(256, 256, kernel_size=(4, 1))\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=(125, 1))\n",
    "        self.avgpool = nn.AvgPool2d(kernel_size=(125, 1))\n",
    "        self.fc1 = nn.Linear(256, 10)\n",
    "        self.fc2 = nn.Linear(10, 150)\n",
    "        self.fc3 = nn.Linear(150, 300)\n",
    "        self.fc4 = nn.Linear(300, 8)  # 8 classes for genre predictions\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        # Sum between the first and third conv layers\n",
    "        x = x[:, :, :, 0] + x[:, :, :, 2]\n",
    "        x = torch.relu(x)\n",
    "        \n",
    "        x = self.maxpool(x)\n",
    "        x = self.avgpool(x)\n",
    "        \n",
    "        # Flatten the tensor for fully connected layers\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda60597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of the network\n",
    "model = MusicGenreNet()\n",
    "\n",
    "# Printing the model architecture\n",
    "print(model)\n",
    "#summary(model, (1, 128, 513))\n",
    "train(model, train_dataset, batch_size=32, num_epochs=50, learning_rate=0.001, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c443ec",
   "metadata": {},
   "source": [
    "# Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "54d3d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioGenreClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(AudioGenreClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # Time-distributed layer\n",
    "        self.time_distributed = nn.Linear(input_size, hidden_size)\n",
    "        \n",
    "        # Bidirectional LSTM layers\n",
    "        self.bilstm = nn.LSTM(256, hidden_size, num_layers = num_layers, bidirectional=True)\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.attention = nn.Linear(hidden_size * 2, 1)\n",
    "        \n",
    "        # Pooling layer\n",
    "        self.pooling = nn.AdaptiveAvgPool1d(1)\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc = nn.Linear(hidden_size * 2, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Time-distributed layer\n",
    "        x = self.time_distributed(x)\n",
    "\n",
    "        # Bidirectional LSTM layers\n",
    "        output, _ = self.bilstm(x)\n",
    "\n",
    "        # Attention mechanism\n",
    "        attention_weights = torch.softmax(self.attention(output), dim=1)\n",
    "        attended_output = torch.sum(attention_weights * output, dim=1)\n",
    "\n",
    "        # Pooling layer\n",
    "        pooled_output = self.pooling(attended_output.permute(0, 1).unsqueeze(2))\n",
    "        \n",
    "        # Reshape and pass through the output layer\n",
    "        pooled_output = pooled_output.squeeze(2)\n",
    "        output = self.fc(pooled_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264b145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainRNN(model, dataset, batch_size, num_epochs, learning_rate):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \",device)\n",
    "    model.to(device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    if not isinstance(dataset, Dataset):\n",
    "        raise ValueError(\"The dataset parameter should be an instance of torch.utils.data.Dataset.\")\n",
    "\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    num_batches = len(data_loader)\n",
    "    \n",
    "    # Initialize the progress bar\n",
    "    progress_bar = tq.tqdm(total=num_batches, unit=\"batch\")\n",
    "    \n",
    "  \n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0 \n",
    "        running_accuracy = 0.0\n",
    "        #initialize correctly predicted samples\n",
    "        \n",
    "        # Initialize the progress bar\n",
    "        progress_bar.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, batch in enumerate(data_loader):\n",
    "            correct = 0 # reset train accuracy each batch\n",
    "            \n",
    "            inputs,labels = batch[0],batch[1]\n",
    "            #print(\"inputs shape:\",inputs.shape,\", content: \",inputs)\n",
    "            #print(\"labels shape:\",labels.shape,\", content: \",labels)\n",
    "            #inputs = inputs.unsqueeze(1)\n",
    "            \n",
    "            # Extract the inputs and targets\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            #print(\"\\noutputs type:\",type(outputs),\"content:\",outputs)\n",
    "            #print(\"\\nlabels type:\",type(labels),\"content:\",labels)\n",
    "\n",
    "            loss = criterion(outputs, labels.float()) #labels need to be a vector of float, not Long\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            #print(\"outputs shape:\",outputs.size(),\"content:\",outputs)\n",
    "            #print(\"labels shape:\",labels.size(),\"content:\",labels)\n",
    "\n",
    "            #calculate train accuracy\n",
    "            for idx, predicted_label in enumerate(outputs):\n",
    "                #print(\"predicted_label size:\",predicted_label.size(),\"content:\",predicted_label)\n",
    "                #print(\"labels[idx] size:\",labels[idx].size(),\"content:\",labels[idx])\n",
    "                max_idx = torch.argmax(predicted_label).item() #index with max argument in the one hot predicted label vector\n",
    "                #print(\"max_idx content:\",max_idx)\n",
    "\n",
    "                if(labels[idx][max_idx].item() == 1):\n",
    "                    correct += 1\n",
    "            \n",
    "            accuracy = 100 * correct / batch_size\n",
    "            running_accuracy += accuracy #epoch running_accuracy\n",
    "            #print(\"Accuracy = {}\".format(accuracy))\n",
    "\n",
    "            \n",
    "            # Update the progress bar description and calculate bps\n",
    "            #progress_bar.set_postfix({\"Loss\": running_loss / (batch_idx + 1)})\n",
    "            average_accuracy = running_accuracy / (batch_idx + 1)\n",
    "            progress_bar.set_postfix({\"Batch accuracy\": accuracy, \"Average accuracy\": average_accuracy})\n",
    "\n",
    "\n",
    "\n",
    "            #bps = (batch_idx + 1) / (time.time() - start_time)\n",
    "\n",
    "            # Update the progress bar\n",
    "            progress_bar.update(1)\n",
    "       \n",
    "\n",
    "\n",
    "        average_loss = running_loss / len(data_loader)\n",
    "        average_accuracy = running_accuracy / len(data_loader)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {average_loss:.4f}. Accuracy: {average_accuracy}\")\n",
    "        progress_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "89cf6716",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainRNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-fc5733ba26ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodelRNN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioGenreClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m513\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodelRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'trainRNN' is not defined"
     ]
    }
   ],
   "source": [
    "modelRNN = AudioGenreClassifier(input_size=513, hidden_size=256, num_layers=5, num_classes=8)\n",
    "trainRNN(modelRNN, train_dataset, batch_size=32, num_epochs=8, learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d343371e",
   "metadata": {},
   "source": [
    "# Raw audio (1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdabb348",
   "metadata": {},
   "source": [
    "## Raw audio dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30092ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom class for accessing our dataset of way audio\n",
    "class MyDatasetRaw(Dataset):\n",
    "    def __init__(self, file_list, labels):\n",
    "        self.file_list = file_list\n",
    "        self.labels=labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # returns a training sample and its label\n",
    "        file_path = self.file_list[idx]\n",
    "        label = torch.tensor(self.labels[idx])\n",
    "        \n",
    "        print(\"opening file:\",file_path)\n",
    "        \n",
    "        #load audio in ram\n",
    "        x = np.load(file_path) #load the MONO audio file from the data/fma_small directory\n",
    "        x=torch.tensor(x)\n",
    "        \n",
    "        return x, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c527e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns file paths list for train, validation and test\n",
    "def get_file_paths():\n",
    "    folder_raw = './data/fma_small'\n",
    "    file_paths_raw = []\n",
    "\n",
    "    AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "    print(\"audio directory: \",AUDIO_DIR)\n",
    "    print(\"Loading tracks.csv...\")\n",
    "    tracks = utils.load('data/fma_metadata/tracks.csv')\n",
    "\n",
    "    #get only the small subset of the dataset\n",
    "    small = tracks[tracks['set', 'subset'] <= 'small']\n",
    "    print(\"small dataset shape:\",small.shape)    \n",
    "\n",
    "    small_training = small.loc[small[('set', 'split')] == 'training']['track']\n",
    "    small_validation = small.loc[small[('set', 'split')] == 'validation']['track']\n",
    "    small_test = small.loc[small[('set', 'split')] == 'test']['track']\n",
    "\n",
    "    print(\"Track.csv: {} training samples, {} validation samples, {} test samples\\n\".format(len(small_training), len(small_validation), len(small_test)))\n",
    "    \n",
    "    #--------------TRAIN----------------------\n",
    "    print(\"Creating train dataset...\")\n",
    "    file_paths_train = []\n",
    "\n",
    "    #we have to get train track_ids from dataframe\n",
    "    track_ids_train = np.array(small_training.index) #get indexes and convert to numpy array\n",
    "    print(f\"There are {len(track_ids_train)} samples. Here's the first ones: {track_ids_train[:10]}\")\n",
    "\n",
    "    for track_id in track_ids_train:\n",
    "        file_path = utils.get_audio_path(AUDIO_DIR,track_id)\n",
    "        file_paths_train.append(file_path)\n",
    "    #sort the files in alphabetical order (important to associate correct labels created using track_id in track.csv)\n",
    "    file_paths_train = np.array(Tcl().call('lsort', '-dict', file_paths_train)) # sort file by name: 2_0,2_1, ... 2_9,3_0, ... 400_0,400_1, ...    \n",
    "    \n",
    "    #--------------VALIDATION----------------------\n",
    "    print(\"Creating validation dataset...\")\n",
    "    file_paths_validation = []\n",
    "\n",
    "    #we have to get train track_ids from dataframe\n",
    "    track_ids_validation = np.array(small_validation.index) #get indexes and convert to numpy array\n",
    "    print(f\"There are {len(track_ids_validation)} samples. Here's the first ones: {track_ids_validation[:10]}\")\n",
    "\n",
    "    for track_id in track_ids_validation:\n",
    "        file_path = utils.get_audio_path(AUDIO_DIR,track_id)\n",
    "        file_paths_validation.append(file_path)\n",
    "    #sort the files in alphabetical order (important to associate correct labels created using track_id in track.csv)\n",
    "    file_paths_validation = np.array(Tcl().call('lsort', '-dict', file_paths_validation)) # sort file by name: 2_0,2_1, ... 2_9,3_0, ... 400_0,400_1, ...    \n",
    "    \n",
    "    #--------------TEST----------------------\n",
    "    print(\"Creating test dataset...\")\n",
    "    file_paths_test = []\n",
    "\n",
    "    #we have to get train track_ids from dataframe\n",
    "    track_ids_test = np.array(small_test.index) #get indexes and convert to numpy array\n",
    "    print(f\"There are {len(track_ids_test)} samples. Here's the first ones: {track_ids_test[:10]}\")\n",
    "\n",
    "    for track_id in track_ids_test:\n",
    "        file_path = utils.get_audio_path(AUDIO_DIR,track_id)\n",
    "        file_paths_test.append(file_path)\n",
    "    #sort the files in alphabetical order (important to associate correct labels created using track_id in track.csv)\n",
    "    file_paths_test = np.array(Tcl().call('lsort', '-dict', file_paths_test)) # sort file by name: 2_0,2_1, ... 2_9,3_0, ... 400_0,400_1, ...    \n",
    "    \n",
    "    \n",
    "    #create the datasets\n",
    "    \n",
    "    return file_paths_train, file_paths_validation, file_paths_test\n",
    "\n",
    "#returns file paths list for train, validation and test for each 3s clip\n",
    "def get_file_paths_split():\n",
    "    folder_raw = './data/fma_small_raw_split'\n",
    "    folder_train = folder_raw + '/train'\n",
    "    folder_validation = folder_raw + '/validation'\n",
    "    folder_test = folder_raw + '/test'\n",
    "    file_paths_raw = []\n",
    "\n",
    "    #--------------TRAIN----------------------\n",
    "    print(\"Creating train dataset...\")\n",
    "    file_paths_train = os.listdir(folder_train)\n",
    "    #sort the files in alphabetical order (important to associate correct labels created using track_id in track.csv)\n",
    "    file_paths_train = np.array(Tcl().call('lsort', '-dict', file_paths_train)) # sort file by name: 2_0,2_1, ... 2_9,3_0, ... 400_0,400_1, ...    \n",
    "    \n",
    "    complete_file_path_train = []\n",
    "    for file in file_paths_train:\n",
    "        complete_file_path_train.append(folder_train + '/' + file)\n",
    "\n",
    "    #--------------VALIDATION----------------------\n",
    "    print(\"Creating validation dataset...\")\n",
    "    file_paths_validation = os.listdir(folder_validation)\n",
    "    #sort the files in alphabetical order (important to associate correct labels created using track_id in track.csv)\n",
    "    file_paths_validation = np.array(Tcl().call('lsort', '-dict', file_paths_validation)) # sort file by name: 2_0,2_1, ... 2_9,3_0, ... 400_0,400_1, ...    \n",
    "    \n",
    "    complete_file_path_validation = []\n",
    "    for file in file_paths_validation:\n",
    "        complete_file_path_validation.append(folder_train + '/' + file)\n",
    "\n",
    "    #--------------TEST----------------------\n",
    "    print(\"Creating test dataset...\")\n",
    "    file_paths_test = os.listdir(folder_test)\n",
    "    #sort the files in alphabetical order (important to associate correct labels created using track_id in track.csv)\n",
    "    file_paths_test = np.array(Tcl().call('lsort', '-dict', file_paths_test)) # sort file by name: 2_0,2_1, ... 2_9,3_0, ... 400_0,400_1, ...    \n",
    "    \n",
    "    complete_file_path_test = []\n",
    "    for file in file_paths_test:\n",
    "        complete_file_path_test.append(folder_train + '/' + file)\n",
    "    \n",
    "    return complete_file_path_train, complete_file_path_validation, complete_file_path_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99825d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating train dataset...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/fma_small_raw_split/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-aa32c4b45983>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfile_paths_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_paths_validation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_paths_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_file_paths_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths_validation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-58-d861a226a0de>\u001b[0m in \u001b[0;36mget_file_paths_split\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;31m#--------------TRAIN----------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating train dataset...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0mfile_paths_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;31m#sort the files in alphabetical order (important to associate correct labels created using track_id in track.csv)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0mfile_paths_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTcl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lsort'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'-dict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_paths_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# sort file by name: 2_0,2_1, ... 2_9,3_0, ... 400_0,400_1, ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/fma_small_raw_split/train'"
     ]
    }
   ],
   "source": [
    "file_paths_train, file_paths_validation, file_paths_test = get_file_paths_split()\n",
    "print(len(file_paths_train))\n",
    "print(len(file_paths_validation))\n",
    "print(len(file_paths_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a891ab30",
   "metadata": {},
   "source": [
    "## Fix wrong sampling rates in the dataset\n",
    "\n",
    "Some songs in the fma_small dataset has a different sampling rate from 44100. Let's fix them by using librosa resampling tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c4f82d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "******Checking sample rates to be 44100 in train set\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'file_paths_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-b2aea6bb4486>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n******Checking sample rates to be\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_sr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"in train set\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_paths_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mtarget_sr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_paths_train' is not defined"
     ]
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "\n",
    "#fix sampling rate\n",
    "target_sr = 44100\n",
    "wrong_sr_list = []\n",
    "\n",
    "\n",
    "print(\"\\n******Checking sample rates to be\",target_sr,\"in train set\")\n",
    "for file in file_paths_train:\n",
    "    x, sr = librosa.load(file,sr=None)\n",
    "    if(sr!=target_sr):\n",
    "        print(\"wrong sr found! value:\",sr,\"resampling to\",target_sr,\"...\")\n",
    "        x = librosa.resample(x,orig_sr=sr,target_sr=target_sr)\n",
    "        print(\"saving new resampled file in\",file,\"...\")\n",
    "        # Write out audio as 24bit PCM WAV\n",
    "        sf.write(file, x, target_sr, format='mp3')    \n",
    "        wrong_sr_list.append(file)\n",
    "        \n",
    "print(\"\\n*****Checking sample rates to be\",target_sr,\"in validation set\")\n",
    "for file in file_paths_validation:\n",
    "    x, sr = librosa.load(file,sr=None)\n",
    "    if(sr!=target_sr):\n",
    "        print(\"wrong sr found! value:\",sr,\"resampling to\",target_sr,\"...\")\n",
    "        x = librosa.resample(x,orig_sr=sr,target_sr=target_sr)\n",
    "        print(\"saving new resampled file in\",file,\"...\")\n",
    "        # Write out audio as 24bit PCM WAV\n",
    "        sf.write(file, x, target_sr, format='mp3')    \n",
    "        wrong_sr_list.append(file)\n",
    "\n",
    "        \n",
    "print(\"\\n*****Checking sample rates to be\",target_sr,\"in test set\")\n",
    "for file in file_paths_test:\n",
    "    x, sr = librosa.load(file,sr=None)\n",
    "    if(sr!=target_sr):\n",
    "        print(\"wrong sr found! value:\",sr,\"resampling to\",target_sr,\"...\")\n",
    "        x = librosa.resample(x,orig_sr=sr,target_sr=target_sr)\n",
    "        print(\"saving new resampled file in\",file,\"...\")\n",
    "        # Write out audio as 24bit PCM WAV\n",
    "        sf.write(file, x, target_sr, format='mp3')    \n",
    "        wrong_sr_list.append(file)\n",
    "        \n",
    "print(\"There were a total of\",len(wrong_sr_list),\"files with wrong sampling rate. Now they have been corrected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f029105b",
   "metadata": {},
   "source": [
    "## Create labels for raw audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33ea1db",
   "metadata": {},
   "source": [
    "We have to take one label each ten from Y_label. Now we are not using 10 clips for each audio but just the whole audio itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25f8b779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train reshaped: 6400\n",
      "Y_validation reshaped: 800\n",
      "Y_test reshaped: 800\n"
     ]
    }
   ],
   "source": [
    "#take a element every ten (not using 10 clips per audio anymore)\n",
    "Y_train_reshaped = [elem for elem in Y_train[0::10]] \n",
    "print(\"Y_train reshaped:\",len(Y_train_reshaped))\n",
    "Y_validation_reshaped = [elem for elem in Y_validation[0::10]] \n",
    "print(\"Y_validation reshaped:\",len(Y_validation_reshaped))\n",
    "Y_test_reshaped = [elem for elem in Y_test[0::10]] \n",
    "print(\"Y_test reshaped:\",len(Y_test_reshaped))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7112c8",
   "metadata": {},
   "source": [
    "## Create dataset for raw audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45f5f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDatasetRaw(file_paths_train, Y_train)\n",
    "validation_dataset = MyDatasetRaw(file_paths_validation, Y_validation)\n",
    "test_dataset = MyDatasetRaw(file_paths_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f89626be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom model class\n",
    "class NNet_Raw(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NNet_Raw, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(32 * 33000, 64)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 8)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa495fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet_Raw2(Module):\n",
    "\n",
    "    def init(self):\n",
    "        super(GlassesNet, self).init()\n",
    "        self.lrelu = LeakyReLU()\n",
    "        self.dropout1 = Dropout(0)\n",
    "        self.dropout2 = Dropout(0.25)\n",
    "        self.layer1 = Conv1d(1, 8, 7, 3)\n",
    "        self.layer2 = Conv1d(8, 16, 5, 2)\n",
    "        self.layer3 = Conv1d(16, 16, 3, 2)\n",
    "        self.layer4 = Conv1d(16, 16, 3, 2)\n",
    "        self.flatten = Flatten()\n",
    "        self.fc = Linear(112, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.dropout1(self.lrelu(self.layer1(x)))\n",
    "        y = self.dropout1(self.lrelu(self.layer2(y)))\n",
    "        y = self.dropout1(self.lrelu(self.layer3(y)))\n",
    "        y = self.dropout2(self.lrelu(self.layer4(y)))\n",
    "        y = self.flatten(y)\n",
    "        y = self.fc(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab3f0168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "421b951a474d47c8a683b5cb6af4677b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?batch/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opening file: ./data/fma_small_raw_split/train/52634_2.npy\n",
      "opening file: ./data/fma_small_raw_split/train/72215_1.npy\n",
      "opening file: ./data/fma_small_raw_split/train/144552_0.npy\n",
      "opening file: ./data/fma_small_raw_split/train/37131_9.npy\n",
      "opening file: ./data/fma_small_raw_split/train/11947_6.npy\n",
      "opening file: ./data/fma_small_raw_split/train/15488_9.npy\n",
      "opening file: ./data/fma_small_raw_split/train/126673_0.npy\n",
      "opening file: ./data/fma_small_raw_split/train/112316_0.npy\n",
      "opening file: ./data/fma_small_raw_split/train/107593_3.npy\n",
      "opening file: ./data/fma_small_raw_split/train/118618_1.npy\n",
      "opening file: ./data/fma_small_raw_split/train/14208_2.npy\n",
      "opening file: ./data/fma_small_raw_split/train/124755_0.npy\n",
      "opening file: ./data/fma_small_raw_split/train/107249_4.npy\n",
      "opening file: ./data/fma_small_raw_split/train/74380_4.npy\n",
      "opening file: ./data/fma_small_raw_split/train/130130_4.npy\n",
      "opening file: ./data/fma_small_raw_split/train/149523_7.npy\n",
      "opening file: ./data/fma_small_raw_split/train/91184_5.npy\n",
      "opening file: ./data/fma_small_raw_split/train/123485_1.npy\n",
      "opening file: ./data/fma_small_raw_split/train/142564_3.npy\n",
      "opening file: ./data/fma_small_raw_split/train/139777_1.npy\n",
      "opening file: ./data/fma_small_raw_split/train/4095_1.npy\n",
      "opening file: ./data/fma_small_raw_split/train/149687_7.npy\n",
      "opening file: ./data/fma_small_raw_split/train/64091_9.npy\n",
      "opening file: ./data/fma_small_raw_split/train/149101_8.npy\n",
      "opening file: ./data/fma_small_raw_split/train/87152_2.npy\n",
      "opening file: ./data/fma_small_raw_split/train/55549_7.npy\n",
      "opening file: ./data/fma_small_raw_split/train/4781_0.npy\n",
      "opening file: ./data/fma_small_raw_split/train/141182_4.npy\n",
      "opening file: ./data/fma_small_raw_split/train/137463_9.npy\n",
      "opening file: ./data/fma_small_raw_split/train/10527_8.npy\n",
      "opening file: ./data/fma_small_raw_split/train/35299_0.npy\n",
      "opening file: ./data/fma_small_raw_split/train/122081_0.npy\n",
      "\n",
      "inputs shape: torch.Size([32, 132300]) , content:  tensor([[ 0.5648,  0.5672,  0.5623,  ..., -0.1151, -0.0920, -0.0730],\n",
      "        [ 0.0545,  0.0361,  0.0034,  ..., -0.0377, -0.0510, -0.0624],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.2064,  0.2073,  0.2065],\n",
      "        ...,\n",
      "        [-0.0985, -0.0975, -0.0948,  ...,  0.0157,  0.0188,  0.0087],\n",
      "        [ 0.2325,  0.1927,  0.0715,  ..., -0.0639, -0.0462, -0.0256],\n",
      "        [ 0.0387,  0.0380,  0.0172,  ..., -0.0179, -0.0216,  0.0848]])\n",
      "\n",
      "labels shape: torch.Size([32]) , content:  tensor([6, 6, 2, 6, 4, 5, 3, 3, 2, 7, 6, 6, 5, 4, 6, 3, 5, 7, 5, 7, 5, 0, 4, 1,\n",
      "        3, 0, 3, 1, 6, 4, 6, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1024x33073 and 1056000x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-3ddff7085393>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mMyModel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNNet_Raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMyModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLEARNING_RATE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-0b7ef43db2fb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataset, batch_size, num_epochs, learning_rate, verbose)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0;31m# Extract the inputs and targets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fma3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-ef7cc7b2557c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fma3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fma3/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fma3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1024x33073 and 1056000x64)"
     ]
    }
   ],
   "source": [
    "MyModel=NNet_Raw2()\n",
    "train_loss_list, train_acc_list, val_loss_list, val_acc_list =train(MyModel, train_dataset, batch_size=BATCH_SIZE, num_epochs=EPOCHS, learning_rate=LEARNING_RATE, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96525097",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f9257b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
