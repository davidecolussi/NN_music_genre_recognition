{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15945d26",
   "metadata": {},
   "source": [
    "# Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6eab989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import pprint\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c4a40d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "audio directory:  ./data/fma_small/\n",
      "Loading tracks.csv...\n",
      "small dataset shape: (8000, 52)\n"
     ]
    }
   ],
   "source": [
    "AUDIO_DIR = os.environ.get('AUDIO_DIR')\n",
    "print(\"audio directory: \",AUDIO_DIR)\n",
    "print(\"Loading tracks.csv...\")\n",
    "tracks = utils.load('data/fma_metadata/tracks.csv')\n",
    "#get only the small subset of the dataset\n",
    "small = tracks[tracks['set', 'subset'] <= 'small']\n",
    "print(\"small dataset shape:\",small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b09d90dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400 training examples, 800 validation examples, 800 testing examples\n"
     ]
    }
   ],
   "source": [
    "#split into train, validation and test sets\n",
    "train = small.index[small['set', 'split'] == 'training']\n",
    "val = small.index[small['set', 'split'] == 'validation']\n",
    "test = small.index[small['set', 'split'] == 'test']\n",
    "\n",
    "print('{} training examples, {} validation examples, {} testing examples'.format(*map(len, [train, val, test])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6217ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genres=utils.load('data/fma_metadata/genres.csv')\n",
    "#list of genres\n",
    "genres_list=genres['title'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1c13fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_labels(labels_set):\n",
    "    lbl_array = labels_set\n",
    "\n",
    "    # Repeat each element 10 times using np.repeat()\n",
    "    expanded_array = np.repeat(lbl_array, 10)\n",
    "\n",
    "    # Create a new Categorical object from the expanded array\n",
    "    expanded_categorical = pd.Categorical(expanded_array)\n",
    "\n",
    "    # Print the expanded categorical variable\n",
    "    return expanded_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0fe763a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'small' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-352eb98ff494>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#retrieve labels for each subset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtr_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msmall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'set'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genre_top'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvl_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msmall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'set'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'validation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genre_top'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mts_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msmall\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'set'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'split'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'track'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'genre_top'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'small' is not defined"
     ]
    }
   ],
   "source": [
    "#retrieve labels for each subset\n",
    "tr_labels = small.loc[small[('set', 'split')] == 'training', ('track', 'genre_top')].values\n",
    "vl_labels = small.loc[small[('set', 'split')] == 'validation', ('track', 'genre_top')].values\n",
    "ts_labels = small.loc[small[('set', 'split')] == 'test', ('track', 'genre_top')].values\n",
    "\n",
    "tr_labels=expand_labels(tr_labels)\n",
    "vl_labels=expand_labels(vl_labels)\n",
    "ts_labels=expand_labels(ts_labels)\n",
    "\n",
    "\n",
    "print('{} training labels, {} validation labels, {} testing labels'.format(*map(len, [tr_labels, vl_labels, ts_labels])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5e3dff",
   "metadata": {},
   "source": [
    "## Generate the STFT small dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34df788",
   "metadata": {},
   "source": [
    "### Let's get all the STFT spectrograms for each track audio in the dataset\n",
    "\n",
    "Some tracks of the original small dataset are corrupted or very small (1-2 seconds), these track will be replaced\n",
    "by a script below with other good tracks of the same genre from the dataset.\n",
    "\n",
    "#### Important\n",
    "Create a directory 'fma_small_stft' with 3 directories inside:\n",
    "- 'train'\n",
    "- 'validation'\n",
    "- 'test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d71a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stft_files(dataset,directory):\n",
    "    print(\"Generating files in the folder:\",directory,\"...\")\n",
    "\n",
    "    track_ids = np.array(dataset)\n",
    "    \n",
    "    error_list = [] #list of tracks which caused errors\n",
    "    progress_bar = 1\n",
    "    for track_id in track_ids:\n",
    "        print(\"track id: \",track_id)\n",
    "\n",
    "        try:\n",
    "            #get the filename using the utils\n",
    "            filename = utils.get_audio_path(AUDIO_DIR, track_id)\n",
    "            print('File: {}'.format(filename))\n",
    "\n",
    "            x, sr = librosa.load(filename, sr=None, mono=True) #load the MONO audio file from the data/fma_small directory\n",
    "            print('Duration: {:.2f}s, {} samples'.format(x.shape[-1] / sr, x.size))\n",
    "\n",
    "            #calculate stft on each 3s clip of the 30s song\n",
    "            for i in range (0,28,3):\n",
    "                start, end = i, i+3 #start and end point of the clip\n",
    "                clip = x[start*sr:end*sr] #extract the clip\n",
    "                #calculate stft using a window of 1024 sample and a hop length of 512 sample\n",
    "                stft = np.abs(librosa.stft(clip, n_fft=1024, hop_length=512))\n",
    "                #resize the spectrogram to become 512 x 128 instead of 512 x 130 (or other shapes)\n",
    "                stft = librosa.util.fix_length(stft, size=513, axis=0)[:, :128]\n",
    "\n",
    "                save_filename = './data/fma_small_stft/' + directory + \"/\" +  str(track_id) + \"_\" + str(i//3)\n",
    "                #print(\"Saving the stft vector in file:\",save_filename) \n",
    "                np.save(save_filename,stft)\n",
    "                #print(\"shape of the stft vector (clip \" + str(i//3) + \"): \", stft.shape)\n",
    "                \n",
    "        except Exception as e: #skip the songs which give error (file corrupted or song too short)\n",
    "            print(\"ERROR on file: \",filename,\"\\nError information:\", e)\n",
    "            error_list.append(filename)\n",
    "            \n",
    "        print(\"Progress:\" + str(progress_bar) + \"/\" + str(len(track_ids)))\n",
    "        progress_bar +=1\n",
    "        if(len(error_list)>0):\n",
    "            print(\"\\n***Some tracks caused errors: \", error_list)\n",
    "        else:\n",
    "            print(\"\\n***Procedure completed without errors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5289487d",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stft_files(train,'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e561e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stft_files(val,'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f05f050",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_stft_files(test,'test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
