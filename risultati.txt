nnet1:
--------------------------------------------
Epoch 1/10: 100%
125/125 [08:20<00:00, 4.20s/batch, avg_loss=1.93, acc=37.1, avg_acc=33.4]
Epoch [1/10], Loss: 1.9256. Accuracy: 33.390625
Epoch 2/10: 100%
125/125 [08:23<00:00, 4.10s/batch, avg_loss=1.86, acc=40.8, avg_acc=40]
Epoch [2/10], Loss: 1.8649. Accuracy: 40.003125
Epoch 3/10: 100%
125/125 [08:02<00:00, 4.18s/batch, avg_loss=1.83, acc=46.1, avg_acc=44]
Epoch [3/10], Loss: 1.8268. Accuracy: 43.959375
Epoch 4/10: 100%
125/125 [08:22<00:00, 5.18s/batch, avg_loss=1.8, acc=46.5, avg_acc=46.4]
Epoch [4/10], Loss: 1.8039. Accuracy: 46.3859375
Epoch 5/10: 100%
125/125 [07:47<00:00, 4.04s/batch, avg_loss=1.78, acc=52.3, avg_acc=48.6]
Epoch [5/10], Loss: 1.7823. Accuracy: 48.634375
Epoch 6/10: 100%
125/125 [08:11<00:00, 4.33s/batch, avg_loss=1.76, acc=52.7, avg_acc=50.6]
Epoch [6/10], Loss: 1.7642. Accuracy: 50.6125
Epoch 7/10: 100%
125/125 [08:24<00:00, 4.22s/batch, avg_loss=1.75, acc=46.7, avg_acc=51.5]
Epoch [7/10], Loss: 1.7547. Accuracy: 51.4796875
Epoch 8/10: 100%
125/125 [08:55<00:00, 5.20s/batch, avg_loss=1.75, acc=49, avg_acc=52]
Epoch [8/10], Loss: 1.7504. Accuracy: 51.9859375
Epoch 9/10: 100%
125/125 [09:18<00:00, 4.32s/batch, avg_loss=1.73, acc=53.1, avg_acc=53.8]
Epoch [9/10], Loss: 1.7321. Accuracy: 53.7625
Epoch 10/10: 100%
125/125 [08:40<00:00, 4.57s/batch, avg_loss=1.72, acc=52, avg_acc=55]
Epoch [10/10], Loss: 1.7209. Accuracy: 55.0125

FROM NOW EPOCHS STARTS FROM 11:
Epoch 1/50: 100%
125/125 [09:37<00:00, 4.61s/batch, avg_loss=1.71, acc=57.2, avg_acc=56]
Epoch [1/50], Loss: 1.7101. Accuracy: 56.0046875
Epoch 2/50: 100%
125/125 [10:09<00:00, 4.43s/batch, avg_loss=1.7, acc=53.3, avg_acc=56.7]
Epoch [2/50], Loss: 1.7038. Accuracy: 56.7125
Epoch 3/50: 100%
125/125 [08:46<00:00, 4.52s/batch, avg_loss=1.7, acc=63.9, avg_acc=57.4]
Epoch [3/50], Loss: 1.6970. Accuracy: 57.4390625
Epoch 4/50: 100%
125/125 [09:47<00:00, 5.08s/batch, avg_loss=1.7, acc=55.5, avg_acc=57.3]
Epoch [4/50], Loss: 1.6977. Accuracy: 57.2828125
Epoch 5/50: 100%
125/125 [10:45<00:00, 5.79s/batch, avg_loss=1.71, acc=55.1, avg_acc=56.4]
Epoch [5/50], Loss: 1.7067. Accuracy: 56.44375
Epoch 6/50: 100%
125/125 [09:40<00:00, 4.77s/batch, avg_loss=1.69, acc=60.5, avg_acc=58.4]
Epoch [6/50], Loss: 1.6878. Accuracy: 58.378125
Epoch 7/50: 100%
125/125 [08:58<00:00, 4.53s/batch, avg_loss=1.69, acc=53.7, avg_acc=57.7]
Epoch [7/50], Loss: 1.6939. Accuracy: 57.7375
Epoch 8/50: 100%
125/125 [09:01<00:00, 4.32s/batch, avg_loss=1.69, acc=57.8, avg_acc=58.6]
Epoch [8/50], Loss: 1.6853. Accuracy: 58.6171875
Epoch 9/50: 100%
125/125 [08:57<00:00, 4.54s/batch, avg_loss=1.68, acc=60.7, avg_acc=59]
Epoch [9/50], Loss: 1.6810. Accuracy: 59.0296875
Epoch 10/50: 100%
125/125 [09:08<00:00, 4.50s/batch, avg_loss=1.68, acc=58.8, avg_acc=59.2]
Epoch [10/50], Loss: 1.6789. Accuracy: 59.25
Epoch 11/50: 100%
125/125 [09:43<00:00, 5.01s/batch, avg_loss=1.69, acc=60.2, avg_acc=58.5]
Epoch [11/50], Loss: 1.6865. Accuracy: 58.5265625
Epoch 12/50: 100%
125/125 [09:53<00:00, 4.70s/batch, avg_loss=1.67, acc=65, avg_acc=60.4]
Epoch [12/50], Loss: 1.6680. Accuracy: 60.3984375
Epoch 13/50: 100%
125/125 [10:23<00:00, 5.89s/batch, avg_loss=1.67, acc=57.4, avg_acc=60.6]
Epoch [13/50], Loss: 1.6663. Accuracy: 60.59375
Epoch 14/50: 100%
125/125 [09:31<00:00, 4.95s/batch, avg_loss=1.66, acc=60.4, avg_acc=61.1]
EARLY STOPPED

---------------------------------------------
GRID SEARCH lr=[0.01, 0.001, 0.0001], batch_size = [128, 256, 512] EPOCHS = 10


Traing model with batch size=128, lr=0.01
Epoch 1/10: 100%
500/500 [10:11<00:00, 1.54s/batch, avg_loss=2.15, acc=17.2, avg_acc=12.5]
Epoch [1/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 2/10: 100%
500/500 [09:00<00:00, 1.07batch/s, avg_loss=2.15, acc=17.2, avg_acc=12.5]
Epoch [2/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 3/10: 100%
500/500 [09:20<00:00, 1.03batch/s, avg_loss=2.15, acc=13.3, avg_acc=12.5]
Epoch [3/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 4/10: 100%
500/500 [08:55<00:00, 1.00s/batch, avg_loss=2.15, acc=10.9, avg_acc=12.5]
Epoch [4/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 5/10: 100%
500/500 [08:41<00:00, 1.04batch/s, avg_loss=2.15, acc=15.6, avg_acc=12.5]
Epoch [5/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 6/10: 100%
500/500 [08:39<00:00, 1.05batch/s, avg_loss=2.15, acc=6.25, avg_acc=12.5]
Epoch [6/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 7/10: 100%
500/500 [08:40<00:00, 1.02batch/s, avg_loss=2.15, acc=18, avg_acc=12.5]
Epoch [7/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 8/10: 100%
500/500 [08:43<00:00, 1.06batch/s, avg_loss=2.15, acc=15.6, avg_acc=12.5]
Epoch [8/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 9/10: 100%
500/500 [08:48<00:00, 1.05s/batch, avg_loss=2.15, acc=13.3, avg_acc=12.5]
Epoch [9/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 10/10: 100%
500/500 [08:43<00:00, 1.03s/batch, avg_loss=2.15, acc=14.1, avg_acc=12.5]
Epoch [10/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
saving model in models/model_lr_0-01_bs_128
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]]]
Traing model with batch size=256, lr=0.01
Epoch 1/10: 100%
250/250 [08:36<00:00, 1.92s/batch, avg_loss=2.15, acc=13.3, avg_acc=12.5]
Epoch [1/10],Train Loss: 2.1484. Train Accuracy: 12.528125 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 2/10: 100%
250/250 [08:31<00:00, 1.96s/batch, avg_loss=2.15, acc=13.7, avg_acc=12.5]
Epoch [2/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 3/10: 100%
250/250 [08:35<00:00, 1.99s/batch, avg_loss=2.15, acc=8.98, avg_acc=12.5]
Epoch [3/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 4/10: 100%
250/250 [08:28<00:00, 2.02s/batch, avg_loss=2.15, acc=11.7, avg_acc=12.5]
Epoch [4/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 5/10: 100%
250/250 [08:30<00:00, 1.87s/batch, avg_loss=2.15, acc=10.5, avg_acc=12.5]
Epoch [5/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 6/10: 100%
250/250 [08:31<00:00, 1.92s/batch, avg_loss=2.15, acc=11.7, avg_acc=12.5]
Epoch [6/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 7/10: 100%
250/250 [08:30<00:00, 1.98s/batch, avg_loss=2.15, acc=14.1, avg_acc=12.5]
Epoch [7/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 8/10: 100%
250/250 [08:30<00:00, 1.90s/batch, avg_loss=2.15, acc=14.1, avg_acc=12.5]
Epoch [8/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 9/10: 100%
250/250 [08:26<00:00, 1.95s/batch, avg_loss=2.15, acc=10.9, avg_acc=12.5]
Epoch [9/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 10/10: 100%
250/250 [08:32<00:00, 1.97s/batch, avg_loss=2.15, acc=9.77, avg_acc=12.5]
Epoch [10/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
saving model in models/model_lr_0-01_bs_256
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]]]
Traing model with batch size=512, lr=0.01
Epoch 1/10: 100%
125/125 [08:44<00:00, 4.49s/batch, avg_loss=2.15, acc=14.3, avg_acc=12.4]
Epoch [1/10],Train Loss: 2.1485. Train Accuracy: 12.44375 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 2/10: 100%
125/125 [08:29<00:00, 3.91s/batch, avg_loss=2.15, acc=10.9, avg_acc=12.5]
Epoch [2/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 3/10: 100%
125/125 [08:33<00:00, 3.87s/batch, avg_loss=2.15, acc=10.7, avg_acc=12.5]
Epoch [3/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 4/10: 100%
125/125 [08:32<00:00, 3.87s/batch, avg_loss=2.15, acc=13.1, avg_acc=12.5]
Epoch [4/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 5/10: 100%
125/125 [08:36<00:00, 3.92s/batch, avg_loss=2.15, acc=13.3, avg_acc=12.5]
Epoch [5/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 6/10: 100%
125/125 [08:33<00:00, 3.84s/batch, avg_loss=2.15, acc=12.9, avg_acc=12.5]
Epoch [6/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 7/10: 100%
125/125 [08:32<00:00, 3.87s/batch, avg_loss=2.15, acc=12.3, avg_acc=12.5]
Epoch [7/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 8/10: 100%
125/125 [08:34<00:00, 3.91s/batch, avg_loss=2.15, acc=10.9, avg_acc=12.5]
Epoch [8/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 9/10: 100%
125/125 [08:38<00:00, 3.98s/batch, avg_loss=2.15, acc=13.3, avg_acc=12.5]
Epoch [9/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 10/10: 100%
125/125 [08:59<00:00, 3.92s/batch, avg_loss=2.15, acc=15.8, avg_acc=12.5]
Epoch [10/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
saving model in models/model_lr_0-01_bs_512
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]]]
Traing model with batch size=128, lr=0.001
Epoch 1/10: 100%
500/500 [09:12<00:00, 1.17s/batch, avg_loss=1.93, acc=32, avg_acc=32.9]
Epoch [1/10],Train Loss: 1.9344. Train Accuracy: 32.859375 Val Loss: 1.9122745493501425 Val Accuracy: 0.35275
Epoch 2/10: 100%
500/500 [09:24<00:00, 1.21s/batch, avg_loss=1.9, acc=31.2, avg_acc=36.3]
Epoch [2/10],Train Loss: 1.9036. Train Accuracy: 36.2671875 Val Loss: 1.9172266080379485 Val Accuracy: 0.353
Epoch 3/10: 100%
500/500 [09:33<00:00, 1.04s/batch, avg_loss=1.89, acc=38.3, avg_acc=37.9]
Epoch [3/10],Train Loss: 1.8897. Train Accuracy: 37.884375 Val Loss: 1.914251158580184 Val Accuracy: 0.35525
Epoch 4/10: 100%
500/500 [09:31<00:00, 1.16s/batch, avg_loss=1.87, acc=43.8, avg_acc=39.7]
Epoch [4/10],Train Loss: 1.8700. Train Accuracy: 39.7453125 Val Loss: 1.8817764599770308 Val Accuracy: 0.387375
Epoch 5/10: 100%
500/500 [09:45<00:00, 1.12s/batch, avg_loss=1.89, acc=39.1, avg_acc=37.9]
Epoch [5/10],Train Loss: 1.8914. Train Accuracy: 37.86875 Val Loss: 1.9169727702736854 Val Accuracy: 0.354
Epoch 6/10: 100%
500/500 [09:33<00:00, 1.03s/batch, avg_loss=1.99, acc=28.1, avg_acc=28.5]
Epoch [6/10],Train Loss: 1.9876. Train Accuracy: 28.528125 Val Loss: 1.996893467321992 Val Accuracy: 0.276875
Epoch 7/10: 100%
500/500 [09:25<00:00, 1.01batch/s, avg_loss=2.09, acc=18.8, avg_acc=18.3]
Epoch [7/10],Train Loss: 2.0914. Train Accuracy: 18.2515625 Val Loss: 2.07832046996057 Val Accuracy: 0.195625
Epoch 8/10: 100%
500/500 [08:45<00:00, 1.02s/batch, avg_loss=2.08, acc=24.2, avg_acc=19.6]
Epoch [8/10],Train Loss: 2.0782. Train Accuracy: 19.5765625 Val Loss: 2.060501457422972 Val Accuracy: 0.2135
Epoch 9/10: 100%
500/500 [08:40<00:00, 1.02s/batch, avg_loss=2.12, acc=13.3, avg_acc=15.8]
Epoch [9/10],Train Loss: 2.1157. Train Accuracy: 15.83125 Val Loss: 2.1483837509155275 Val Accuracy: 0.125625
Epoch 10/10: 100%
500/500 [08:41<00:00, 1.02batch/s, avg_loss=2.15, acc=15.6, avg_acc=12.5]
Epoch [10/10],Train Loss: 2.1490. Train Accuracy: 12.5015625 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
saving model in models/model_lr_0-001_bs_128
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]]]
Traing model with batch size=256, lr=0.001
Epoch 1/10: 100%
250/250 [08:44<00:00, 2.11s/batch, avg_loss=1.91, acc=40.6, avg_acc=35.1]
Epoch [1/10],Train Loss: 1.9106. Train Accuracy: 35.0859375 Val Loss: 1.896410737067461 Val Accuracy: 0.3675
Epoch 2/10: 100%
250/250 [09:01<00:00, 2.09s/batch, avg_loss=1.86, acc=43, avg_acc=40.4]
Epoch [2/10],Train Loss: 1.8616. Train Accuracy: 40.4421875 Val Loss: 1.8522914710491896 Val Accuracy: 0.412375
Epoch 3/10: 100%
250/250 [09:09<00:00, 2.21s/batch, avg_loss=1.84, acc=47.7, avg_acc=42.8]
Epoch [3/10],Train Loss: 1.8395. Train Accuracy: 42.84375 Val Loss: 1.8260197767913342 Val Accuracy: 0.439375
Epoch 4/10: 100%
250/250 [09:18<00:00, 2.25s/batch, avg_loss=1.82, acc=53.1, avg_acc=45.2]
Epoch [4/10],Train Loss: 1.8156. Train Accuracy: 45.21875 Val Loss: 1.8525366085767745 Val Accuracy: 0.4135
Epoch 5/10: 100%
250/250 [09:20<00:00, 2.07s/batch, avg_loss=1.8, acc=48, avg_acc=47.3]
Epoch [5/10],Train Loss: 1.7958. Train Accuracy: 47.28125 Val Loss: 1.8349460310041905 Val Accuracy: 0.433125
Epoch 6/10: 100%
250/250 [09:28<00:00, 2.20s/batch, avg_loss=1.8, acc=51.6, avg_acc=47.4]
Epoch [6/10],Train Loss: 1.7959. Train Accuracy: 47.403125 Val Loss: 1.8046241473853588 Val Accuracy: 0.465375
Epoch 7/10: 100%
250/250 [09:37<00:00, 2.12s/batch, avg_loss=1.79, acc=51.2, avg_acc=47.9]
Epoch [7/10],Train Loss: 1.7912. Train Accuracy: 47.8765625 Val Loss: 1.8275287748426199 Val Accuracy: 0.440875
Epoch 8/10: 100%
250/250 [09:43<00:00, 2.24s/batch, avg_loss=1.79, acc=53.1, avg_acc=48.1]
Epoch [8/10],Train Loss: 1.7880. Train Accuracy: 48.10625 Val Loss: 1.8104271434694528 Val Accuracy: 0.4605
Epoch 9/10: 100%
250/250 [09:43<00:00, 2.13s/batch, avg_loss=1.77, acc=51.6, avg_acc=50.5]
Epoch [9/10],Train Loss: 1.7655. Train Accuracy: 50.4625 Val Loss: 1.8292202703207732 Val Accuracy: 0.4445
Epoch 10/10: 100%
250/250 [09:57<00:00, 2.35s/batch, avg_loss=1.77, acc=43.4, avg_acc=50.4]
Epoch [10/10],Train Loss: 1.7659. Train Accuracy: 50.4140625 Val Loss: 1.8237933877855539 Val Accuracy: 0.447125
saving model in models/model_lr_0-001_bs_256
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]], [[0.3675, 0.412375, 0.439375, 0.4135, 0.433125, 0.465375, 0.440875, 0.4605, 0.4445, 0.447125], [1.896410737067461, 1.8522914710491896, 1.8260197767913342, 1.8525366085767745, 1.8349460310041905, 1.8046241473853588, 1.8275287748426199, 1.8104271434694528, 1.8292202703207732, 1.8237933877855539]]]
Traing model with batch size=512, lr=0.001
Epoch 1/10: 100%
125/125 [08:44<00:00, 4.10s/batch, avg_loss=1.91, acc=39.5, avg_acc=34.6]
Epoch [1/10],Train Loss: 1.9143. Train Accuracy: 34.6125 Val Loss: 1.882827129766345 Val Accuracy: 0.376375
Epoch 2/10: 100%
125/125 [08:47<00:00, 4.00s/batch, avg_loss=1.86, acc=43.2, avg_acc=40.7]
Epoch [2/10],Train Loss: 1.8583. Train Accuracy: 40.7390625 Val Loss: 1.8444042218923569 Val Accuracy: 0.42575
Epoch 3/10: 100%
125/125 [08:52<00:00, 4.23s/batch, avg_loss=1.83, acc=42, avg_acc=44]
Epoch [3/10],Train Loss: 1.8276. Train Accuracy: 43.9921875 Val Loss: 1.8413038718253374 Val Accuracy: 0.428875
Epoch 4/10: 100%
125/125 [09:00<00:00, 4.18s/batch, avg_loss=1.82, acc=46.1, avg_acc=45.1]
Epoch [4/10],Train Loss: 1.8172. Train Accuracy: 45.0578125 Val Loss: 1.8464463885724545 Val Accuracy: 0.42025
Epoch 5/10: 100%
125/125 [09:11<00:00, 4.32s/batch, avg_loss=1.8, acc=43.8, avg_acc=47]
Epoch [5/10],Train Loss: 1.7989. Train Accuracy: 46.990625 Val Loss: 1.8387476181536913 Val Accuracy: 0.428
Epoch 6/10: 100%
125/125 [09:07<00:00, 4.21s/batch, avg_loss=1.78, acc=52, avg_acc=49.1]
Epoch [6/10],Train Loss: 1.7782. Train Accuracy: 49.08125 Val Loss: 1.8239915691167117 Val Accuracy: 0.4415
Epoch 7/10: 100%
125/125 [09:03<00:00, 4.19s/batch, avg_loss=1.75, acc=50.6, avg_acc=51.6]
Epoch [7/10],Train Loss: 1.7536. Train Accuracy: 51.5921875 Val Loss: 1.8128462145626545 Val Accuracy: 0.455125
Epoch 8/10: 100%
125/125 [09:40<00:00, 4.23s/batch, avg_loss=1.75, acc=50.8, avg_acc=52.4]
Epoch [8/10],Train Loss: 1.7462. Train Accuracy: 52.3625 Val Loss: 1.8042407598495482 Val Accuracy: 0.46675
Epoch 9/10: 100%
125/125 [09:07<00:00, 4.14s/batch, avg_loss=1.74, acc=54.1, avg_acc=53.4]
Epoch [9/10],Train Loss: 1.7367. Train Accuracy: 53.3984375 Val Loss: 1.7893701848238706 Val Accuracy: 0.48225
Epoch 10/10: 100%
125/125 [09:28<00:00, 4.34s/batch, avg_loss=1.74, acc=55.9, avg_acc=53.5]
Epoch [10/10],Train Loss: 1.7353. Train Accuracy: 53.521875 Val Loss: 1.7999915072023869 Val Accuracy: 0.470375
saving model in models/model_lr_0-001_bs_512
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]], [[0.3675, 0.412375, 0.439375, 0.4135, 0.433125, 0.465375, 0.440875, 0.4605, 0.4445, 0.447125], [1.896410737067461, 1.8522914710491896, 1.8260197767913342, 1.8525366085767745, 1.8349460310041905, 1.8046241473853588, 1.8275287748426199, 1.8104271434694528, 1.8292202703207732, 1.8237933877855539]], [[0.376375, 0.42575, 0.428875, 0.42025, 0.428, 0.4415, 0.455125, 0.46675, 0.48225, 0.470375], [1.882827129766345, 1.8444042218923569, 1.8413038718253374, 1.8464463885724545, 1.8387476181536913, 1.8239915691167117, 1.8128462145626545, 1.8042407598495482, 1.7893701848238706, 1.7999915072023869]]]
Traing model with batch size=128, lr=0.0001
Epoch 1/10: 100%
500/500 [08:57<00:00, 1.07s/batch, avg_loss=1.92, acc=32.8, avg_acc=35.2]
Epoch [1/10],Train Loss: 1.9151. Train Accuracy: 35.1765625 Val Loss: 1.8935416251718997 Val Accuracy: 0.371375
Epoch 2/10: 100%
500/500 [08:50<00:00, 1.04s/batch, avg_loss=1.86, acc=40.6, avg_acc=41.1]
Epoch [2/10],Train Loss: 1.8556. Train Accuracy: 41.1390625 Val Loss: 1.8745876116603613 Val Accuracy: 0.384375
Epoch 3/10: 100%
500/500 [08:50<00:00, 1.05s/batch, avg_loss=1.83, acc=54.7, avg_acc=44]
Epoch [3/10],Train Loss: 1.8275. Train Accuracy: 44.0453125 Val Loss: 1.8485859577804804 Val Accuracy: 0.412625
Epoch 4/10: 100%
500/500 [08:49<00:00, 1.08s/batch, avg_loss=1.8, acc=48.4, avg_acc=47.2]
Epoch [4/10],Train Loss: 1.7984. Train Accuracy: 47.203125 Val Loss: 1.849452141225338 Val Accuracy: 0.41175
Epoch 5/10: 100%
500/500 [08:51<00:00, 1.00batch/s, avg_loss=1.78, acc=43, avg_acc=49.4]
Epoch [5/10],Train Loss: 1.7769. Train Accuracy: 49.3703125 Val Loss: 1.8201128201037646 Val Accuracy: 0.44825
Epoch 6/10: 100%
500/500 [09:08<00:00, 1.00s/batch, avg_loss=1.76, acc=53.9, avg_acc=51.5]
Epoch [6/10],Train Loss: 1.7571. Train Accuracy: 51.55 Val Loss: 1.8425580082833768 Val Accuracy: 0.428875
Epoch 7/10: 100%
500/500 [08:49<00:00, 1.02s/batch, avg_loss=1.74, acc=45.3, avg_acc=52.8]
Epoch [7/10],Train Loss: 1.7429. Train Accuracy: 52.8484375 Val Loss: 1.808242661178112 Val Accuracy: 0.459625
Epoch 8/10: 100%
500/500 [09:17<00:00, 1.03batch/s, avg_loss=1.73, acc=48.4, avg_acc=54.2]
Epoch [8/10],Train Loss: 1.7301. Train Accuracy: 54.2140625 Val Loss: 1.8058343342989682 Val Accuracy: 0.4645
Epoch 9/10: 100%
500/500 [08:58<00:00, 1.02batch/s, avg_loss=1.72, acc=60.2, avg_acc=55.5]
Epoch [9/10],Train Loss: 1.7184. Train Accuracy: 55.5015625 Val Loss: 1.806230291634798 Val Accuracy: 0.473625
Epoch 10/10: 100%
500/500 [08:49<00:00, 1.01batch/s, avg_loss=1.71, acc=55.5, avg_acc=56.7]
Epoch [10/10],Train Loss: 1.7064. Train Accuracy: 56.6515625 Val Loss: 1.8007425208240748 Val Accuracy: 0.473125
saving model in models/model_lr_0-0001_bs_128
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]], [[0.3675, 0.412375, 0.439375, 0.4135, 0.433125, 0.465375, 0.440875, 0.4605, 0.4445, 0.447125], [1.896410737067461, 1.8522914710491896, 1.8260197767913342, 1.8525366085767745, 1.8349460310041905, 1.8046241473853588, 1.8275287748426199, 1.8104271434694528, 1.8292202703207732, 1.8237933877855539]], [[0.376375, 0.42575, 0.428875, 0.42025, 0.428, 0.4415, 0.455125, 0.46675, 0.48225, 0.470375], [1.882827129766345, 1.8444042218923569, 1.8413038718253374, 1.8464463885724545, 1.8387476181536913, 1.8239915691167117, 1.8128462145626545, 1.8042407598495482, 1.7893701848238706, 1.7999915072023869]], [[0.371375, 0.384375, 0.412625, 0.41175, 0.44825, 0.428875, 0.459625, 0.4645, 0.473625, 0.473125], [1.8935416251718997, 1.8745876116603613, 1.8485859577804804, 1.849452141225338, 1.8201128201037646, 1.8425580082833768, 1.808242661178112, 1.8058343342989682, 1.806230291634798, 1.8007425208240748]]]
Traing model with batch size=256, lr=0.0001
Epoch 1/10: 100%
250/250 [09:34<00:00, 2.12s/batch, avg_loss=1.93, acc=35.5, avg_acc=32.8]
Epoch [1/10],Train Loss: 1.9325. Train Accuracy: 32.8109375 Val Loss: 1.8994971818625928 Val Accuracy: 0.35675
Epoch 2/10: 100%
250/250 [11:29<00:00, 2.33s/batch, avg_loss=1.87, acc=43.8, avg_acc=39.8]
Epoch [2/10],Train Loss: 1.8675. Train Accuracy: 39.80625 Val Loss: 1.8854113938063384 Val Accuracy: 0.372125
Epoch 3/10: 100%
250/250 [11:04<00:00, 2.38s/batch, avg_loss=1.85, acc=44.9, avg_acc=42.3]
Epoch [3/10],Train Loss: 1.8452. Train Accuracy: 42.2765625 Val Loss: 1.8769579823166131 Val Accuracy: 0.385125
Epoch 4/10: 100%
250/250 [09:24<00:00, 2.00s/batch, avg_loss=1.82, acc=47.7, avg_acc=44.6]
Epoch [4/10],Train Loss: 1.8229. Train Accuracy: 44.5640625 Val Loss: 1.8551166446208953 Val Accuracy: 0.40975
Epoch 5/10: 100%
250/250 [10:21<00:00, 2.34s/batch, avg_loss=1.81, acc=46.5, avg_acc=46.4]
Epoch [5/10],Train Loss: 1.8053. Train Accuracy: 46.4140625 Val Loss: 1.8545966487824916 Val Accuracy: 0.406625
Epoch 6/10: 100%
250/250 [10:17<00:00, 2.62s/batch, avg_loss=1.79, acc=45.7, avg_acc=48.2]
Epoch [6/10],Train Loss: 1.7896. Train Accuracy: 48.209375 Val Loss: 1.8329055020064116 Val Accuracy: 0.428875
Epoch 7/10: 100%
250/250 [09:54<00:00, 2.15s/batch, avg_loss=1.77, acc=52.3, avg_acc=50]
Epoch [7/10],Train Loss: 1.7724. Train Accuracy: 49.9828125 Val Loss: 1.8317571551799774 Val Accuracy: 0.439375
Epoch 8/10: 100%
250/250 [10:42<00:00, 2.53s/batch, avg_loss=1.76, acc=52.3, avg_acc=51.1]
Epoch [8/10],Train Loss: 1.7615. Train Accuracy: 51.0796875 Val Loss: 1.8060852632671596 Val Accuracy: 0.465375
Epoch 9/10: 100%
250/250 [12:08<00:00, 2.92s/batch, avg_loss=1.75, acc=51.6, avg_acc=52.3]
Epoch [9/10],Train Loss: 1.7491. Train Accuracy: 52.3265625 Val Loss: 1.813155138656497 Val Accuracy: 0.4585
Epoch 10/10: 100%
250/250 [20:17<00:00, 3.22s/batch, avg_loss=1.74, acc=57.4, avg_acc=53.4]
Epoch [10/10],Train Loss: 1.7382. Train Accuracy: 53.421875 Val Loss: 1.8029643515199423 Val Accuracy: 0.4685
saving model in models/model_lr_0-0001_bs_256
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]], [[0.3675, 0.412375, 0.439375, 0.4135, 0.433125, 0.465375, 0.440875, 0.4605, 0.4445, 0.447125], [1.896410737067461, 1.8522914710491896, 1.8260197767913342, 1.8525366085767745, 1.8349460310041905, 1.8046241473853588, 1.8275287748426199, 1.8104271434694528, 1.8292202703207732, 1.8237933877855539]], [[0.376375, 0.42575, 0.428875, 0.42025, 0.428, 0.4415, 0.455125, 0.46675, 0.48225, 0.470375], [1.882827129766345, 1.8444042218923569, 1.8413038718253374, 1.8464463885724545, 1.8387476181536913, 1.8239915691167117, 1.8128462145626545, 1.8042407598495482, 1.7893701848238706, 1.7999915072023869]], [[0.371375, 0.384375, 0.412625, 0.41175, 0.44825, 0.428875, 0.459625, 0.4645, 0.473625, 0.473125], [1.8935416251718997, 1.8745876116603613, 1.8485859577804804, 1.849452141225338, 1.8201128201037646, 1.8425580082833768, 1.808242661178112, 1.8058343342989682, 1.806230291634798, 1.8007425208240748]], [[0.35675, 0.372125, 0.385125, 0.40975, 0.406625, 0.428875, 0.439375, 0.465375, 0.4585, 0.4685], [1.8994971818625928, 1.8854113938063384, 1.8769579823166131, 1.8551166446208953, 1.8545966487824916, 1.8329055020064116, 1.8317571551799774, 1.8060852632671596, 1.813155138656497, 1.8029643515199423]]]
Traing model with batch size=512, lr=0.0001
Epoch 1/10: 100%
125/125 [12:11<00:00, 4.79s/batch, avg_loss=1.97, acc=39.1, avg_acc=28.9]
Epoch [1/10],Train Loss: 1.9654. Train Accuracy: 28.95 Val Loss: 1.9048996717184783 Val Accuracy: 0.365125
Epoch 2/10: 100%
125/125 [09:44<00:00, 4.12s/batch, avg_loss=1.88, acc=36.7, avg_acc=39.4]
Epoch [2/10],Train Loss: 1.8758. Train Accuracy: 39.4140625 Val Loss: 1.883847340464592 Val Accuracy: 0.380875
Epoch 3/10: 100%
125/125 [10:30<00:00, 3.98s/batch, avg_loss=1.86, acc=38.5, avg_acc=41.2]
Epoch [3/10],Train Loss: 1.8565. Train Accuracy: 41.2125 Val Loss: 1.8755802492052316 Val Accuracy: 0.3845
Epoch 4/10: 100%
125/125 [08:55<00:00, 4.05s/batch, avg_loss=1.84, acc=43.6, avg_acc=43.1]
Epoch [4/10],Train Loss: 1.8391. Train Accuracy: 43.1046875 Val Loss: 1.8552769204229116 Val Accuracy: 0.405
Epoch 5/10: 100%
125/125 [08:57<00:00, 4.18s/batch, avg_loss=1.82, acc=46.9, avg_acc=45.1]
Epoch [5/10],Train Loss: 1.8202. Train Accuracy: 45.0546875 Val Loss: 1.838795747473836 Val Accuracy: 0.42425
Epoch 6/10: 100%
125/125 [08:55<00:00, 4.02s/batch, avg_loss=1.8, acc=47.3, avg_acc=46.8]
Epoch [6/10],Train Loss: 1.8045. Train Accuracy: 46.80625 Val Loss: 1.8407539522200822 Val Accuracy: 0.424625
Epoch 7/10: 100%
125/125 [09:48<00:00, 4.65s/batch, avg_loss=1.8, acc=49.2, avg_acc=47.6]
Epoch [7/10],Train Loss: 1.7951. Train Accuracy: 47.6171875 Val Loss: 1.826495782598853 Val Accuracy: 0.434375
Epoch 8/10: 100%
125/125 [10:44<00:00, 4.43s/batch, avg_loss=1.79, acc=45.9, avg_acc=48.7]
Epoch [8/10],Train Loss: 1.7855. Train Accuracy: 48.7125 Val Loss: 1.8369564942121506 Val Accuracy: 0.432125
Epoch 9/10: 100%
125/125 [09:40<00:00, 4.38s/batch, avg_loss=1.77, acc=49, avg_acc=50.1]
Epoch [9/10],Train Loss: 1.7722. Train Accuracy: 50.0890625 Val Loss: 1.8237806998342276 Val Accuracy: 0.44325
Epoch 10/10: 100%
125/125 [11:23<00:00, 4.67s/batch, avg_loss=1.76, acc=52.3, avg_acc=50.9]
Epoch [10/10],Train Loss: 1.7646. Train Accuracy: 50.9234375 Val Loss: 1.816964417949319 Val Accuracy: 0.4535
saving model in models/model_lr_0-0001_bs_512
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]], [[0.3675, 0.412375, 0.439375, 0.4135, 0.433125, 0.465375, 0.440875, 0.4605, 0.4445, 0.447125], [1.896410737067461, 1.8522914710491896, 1.8260197767913342, 1.8525366085767745, 1.8349460310041905, 1.8046241473853588, 1.8275287748426199, 1.8104271434694528, 1.8292202703207732, 1.8237933877855539]], [[0.376375, 0.42575, 0.428875, 0.42025, 0.428, 0.4415, 0.455125, 0.46675, 0.48225, 0.470375], [1.882827129766345, 1.8444042218923569, 1.8413038718253374, 1.8464463885724545, 1.8387476181536913, 1.8239915691167117, 1.8128462145626545, 1.8042407598495482, 1.7893701848238706, 1.7999915072023869]], [[0.371375, 0.384375, 0.412625, 0.41175, 0.44825, 0.428875, 0.459625, 0.4645, 0.473625, 0.473125], [1.8935416251718997, 1.8745876116603613, 1.8485859577804804, 1.849452141225338, 1.8201128201037646, 1.8425580082833768, 1.808242661178112, 1.8058343342989682, 1.806230291634798, 1.8007425208240748]], [[0.35675, 0.372125, 0.385125, 0.40975, 0.406625, 0.428875, 0.439375, 0.465375, 0.4585, 0.4685], [1.8994971818625928, 1.8854113938063384, 1.8769579823166131, 1.8551166446208953, 1.8545966487824916, 1.8329055020064116, 1.8317571551799774, 1.8060852632671596, 1.813155138656497, 1.8029643515199423]], [[0.365125, 0.380875, 0.3845, 0.405, 0.42425, 0.424625, 0.434375, 0.432125, 0.44325, 0.4535], [1.9048996717184783, 1.883847340464592, 1.8755802492052316, 1.8552769204229116, 1.838795747473836, 1.8407539522200822, 1.826495782598853, 1.8369564942121506, 1.8237806998342276, 1.816964417949319]]]
 ---------------------------------------------------------------------------
-----------------------------------------------------------------------------
-----------------------------------------------------------------------------



NNET1 + BN 

dataset: fma_small_stft_transposed (normalized)
batch_size=128, num_epochs=20, learning_rate=0.001, Adam(weight_decay=1e-5)

Epoch 1/20: 100%
500/500 [10:36<00:00, 1.04s/batch, avg_loss=1.83, acc=50, avg_acc=44.6]
[[538   8  16  20  22 122 270   4]
 [ 88  26 105 145 191 192 176  77]
 [ 33  38 514  38  69 163   4 141]
 [ 14  21  36 668 103 117  21  20]
 [ 15   5 113  76 493  59  95 144]
 [ 48  12  31  40 282 428 105  54]
 [ 89   1   8  10 154 140 511  87]
 [  1  22 118  96 298 142  64 259]]
Epoch [1/20],Train Loss: 1.8274. Train Accuracy: 44.6109375 Val Loss: 1.8363054718226195 Val Accuracy: tensor([42.9625])
Epoch 2/20: 100%
500/500 [09:21<00:00, 1.01s/batch, avg_loss=1.75, acc=50, avg_acc=51.7]
[[507  43  65   6  20  54 302   3]
 [ 85  70 195 123 218  84 163  62]
 [  5  45 583  76 137  31   3 120]
 [ 18  83 161 536  86  82  12  22]
 [  9  12 146  90 544  21  77 101]
 [ 38  15 157  38 218 362 121  51]
 [ 95  36  21  23 136  47 557  85]
 [  0  75 259 150 170  36  24 286]]
Epoch [2/20],Train Loss: 1.7536. Train Accuracy: 51.715625 Val Loss: 1.8353335098475219 Val Accuracy: tensor([43.0625])
Epoch 3/20: 100%
500/500 [09:15<00:00, 1.27s/batch, avg_loss=1.72, acc=54.7, avg_acc=55.1]
[[509  50  43   4  31  72 290   1]
 [ 69  87 139 107 288  69 180  61]
 [  6  82 638  31  59  46   4 134]
 [  6 124  88 558 136  44  21  23]
 [  1  18 126  42 606  21  83 103]
 [ 19  20  88  23 266 415 119  50]
 [ 68  21  14   9 162  46 592  88]
 [  0  86 145  70 334  21  62 282]]
Epoch [3/20],Train Loss: 1.7208. Train Accuracy: 55.125 Val Loss: 1.8053544578552245 Val Accuracy: tensor([46.0875])
Epoch 4/20: 100%
500/500 [09:38<00:00, 1.20s/batch, avg_loss=1.7, acc=56.2, avg_acc=57.4]
[[639  69  34   9  22  52 164  11]
 [ 97 161  89 105 244  81 156  67]
 [  9 197 465  29 127  62   3 108]
 [ 16 151  25 620  99  40  22  27]
 [  8  28  68  47 604  23 117 105]
 [ 32  50  57  29 223 482  76  51]
 [117  55  11   9 104  57 572  75]
 [  0 174  55  80 306  31  29 325]]
Epoch [4/20],Train Loss: 1.6967. Train Accuracy: 57.4375 Val Loss: 1.7836991310715675 Val Accuracy: tensor([48.3500])
Epoch 5/20: 100%
500/500 [10:12<00:00, 1.17s/batch, avg_loss=1.68, acc=59.4, avg_acc=59.3]
[[373  91  18   8  43 118 349   0]
 [ 57 106 105 115 277 122 158  60]
 [  8 104 612  38  88  63   6  81]
 [  2 131  58 615  94  63  23  14]
 [  2  25 107  54 629  17  91  75]
 [  9  24  39  22 206 593  60  47]
 [ 57  46   9   6 121  88 570 103]
 [  0 126 129  95 331  37  48 234]]
Epoch [5/20],Train Loss: 1.6787. Train Accuracy: 59.2984375 Val Loss: 1.8009120660424232 Val Accuracy: tensor([46.6500])
Epoch 6/20: 100%
500/500 [09:45<00:00, 1.07s/batch, avg_loss=1.66, acc=57.8, avg_acc=60.7]
[[307 130  37   8  30  87 391  10]
 [ 33 181 133 107 166  80 164 136]
 [  1 117 571  36  10  19   6 240]
 [  0 267  54 527  65  22  25  40]
 [  2  29  69  62 512  14  77 235]
 [  5  53 118  24 162 465  77  96]
 [ 32  51   6  11 101  55 596 148]
 [  0 128  58  74 214  18  59 449]]
Epoch [6/20],Train Loss: 1.6644. Train Accuracy: 60.7203125 Val Loss: 1.8136915127038955 Val Accuracy: tensor([45.1000])
Epoch 7/20: 100%
500/500 [11:50<00:00, 1.92s/batch, avg_loss=1.65, acc=62.5, avg_acc=62]
[[582  48  22  17  15 102 202  12]
 [ 85 147  84 112 192 154 116 110]
 [  6 119 501  16  85  96   9 168]
 [  7 178  44 603  48  62  28  30]
 [  4  26  57  68 568  47  70 160]
 [ 24  51  52  21 202 519  59  72]
 [115  24   5   7 114 111 504 120]
 [  0 114  72  59 172  49  64 470]]
Epoch [7/20],Train Loss: 1.6523. Train Accuracy: 61.996875 Val Loss: 1.781291944950819 Val Accuracy: tensor([48.6750])
Epoch 8/20: 100%
500/500 [18:17<00:00, 1.70s/batch, avg_loss=1.64, acc=70.3, avg_acc=63.2]
[[574  67  36   2  45  72 199   5]
 [ 76 154 126 109 270  59 123  83]
 [  4  96 673  40  41  12   3 131]
 [ 14 239  59 552  81  10  15  30]
 [  4  15  62  44 627  20  60 168]
 [ 12  56 116  25 181 505  44  61]
 [101  48  11  21 140  70 494 115]
 [  0 141  91 110 333  12  32 281]]
Epoch [8/20],Train Loss: 1.6407. Train Accuracy: 63.1625 Val Loss: 1.7876674955636263 Val Accuracy: tensor([48.2500])
Epoch 9/20: 100%
500/500 [11:02<00:00, 1.80s/batch, avg_loss=1.63, acc=64.8, avg_acc=64.6]
[[523 100  34   8  38 108 181   8]
 [ 76 185 127  97 237  63 102 113]
 [  2 158 659  22  49  10   0 100]
 [  5 214  59 581  82  20  12  27]
 [  4  45 102  35 612  13  49 140]
 [ 26  76  99  23 169 504  25  78]
 [ 94  90   9   9 132  73 464 129]
 [  0 136 113  65 220  15  18 433]]
Epoch [9/20],Train Loss: 1.6268. Train Accuracy: 64.590625 Val Loss: 1.774259746402502 Val Accuracy: tensor([49.5125])
Epoch 10/20: 100%
500/500 [10:47<00:00, 1.02s/batch, avg_loss=1.62, acc=70.3, avg_acc=65.6]
[[552  66  28  17  40  53 238   6]
 [ 63 126 144 131 248  69 128  91]
 [  1  82 722  49  20  15   4 107]
 [  7  85  43 691  94  24  31  25]
 [  6  16  96  60 552  35  60 175]
 [ 20  48 116  35 144 532  41  64]
 [ 90  42  13  14 103  70 530 138]
 [  2 110 131 107 229  20  31 370]]
Epoch [10/20],Train Loss: 1.6166. Train Accuracy: 65.6265625 Val Loss: 1.7602042745500803 Val Accuracy: tensor([50.9375])
Epoch 11/20: 100%
500/500 [14:12<00:00, 1.51s/batch, avg_loss=1.61, acc=59.4, avg_acc=66.5]
[[365 110  15   8  39  42 418   3]
 [ 41 160  45 104 243  49 244 114]
 [  2 178 446  50  59  32  41 192]
 [  2 185  24 602  90  14  60  23]
 [  0  20  42  46 618  11 103 160]
 [  7  59  52  21 225 421 148  67]
 [ 21  46   2   7 101  22 712  89]
 [  0 113  48  75 272  10 117 365]]
Epoch [11/20],Train Loss: 1.6077. Train Accuracy: 66.5453125 Val Loss: 1.8083399274498224 Val Accuracy: tensor([46.1125])
Epoch 12/20: 100%
500/500 [16:11<00:00, 2.14s/batch, avg_loss=1.6, acc=68, avg_acc=67.3]
[[567  68  23   1  39  51 247   4]
 [ 75 179 111  62 214  88 171 100]
 [  3 142 588  16  39  49   9 154]
 [ 12 330  41 440  79  34  36  28]
 [  6  29  98  29 547  58  90 143]
 [ 28  60  62  15 115 597  63  60]
 [ 95  49   6   2 135  44 568 101]
 [  0 158 105  39 218  35  42 403]]
Epoch [12/20],Train Loss: 1.5992. Train Accuracy: 67.3125 Val Loss: 1.7806505072116852 Val Accuracy: tensor([48.6125])
Epoch 13/20: 100%
500/500 [12:52<00:00, 1.30s/batch, avg_loss=1.59, acc=67.2, avg_acc=68]
[[618  43  20  15  58  97 145   4]
 [117  94 101 161 258  90 105  74]
 [ 12 122 634  53  54  37   8  80]
 [ 15  77  31 743  71  33  16  14]
 [  9  16 110  76 621  20  52  96]
 [ 27  24  83  33 178 582  25  48]
 [148  44  16   9 145  97 457  84]
 [  1 150 109  98 300  20  44 278]]
Epoch [13/20],Train Loss: 1.5925. Train Accuracy: 67.9546875 Val Loss: 1.7658439722061157 Val Accuracy: tensor([50.3375])
Epoch 14/20: 100%
500/500 [12:06<00:00, 1.45s/batch, avg_loss=1.58, acc=68.8, avg_acc=69.4]
[[522 118  32   8  25 105 187   3]
 [ 56 183 116 102 203 139 149  52]
 [  2 153 586  13  92  75   5  74]
 [  2 250  44 568  59  45  13  19]
 [  6  49 108  43 573  46  86  89]
 [ 10  41  51  21 172 655  26  24]
 [ 77  91  10   6 123  72 542  79]
 [  0 240 156  47 200  45 102 210]]
Epoch [14/20],Train Loss: 1.5792. Train Accuracy: 69.446875 Val Loss: 1.7884694383293391 Val Accuracy: tensor([47.9875])
Epoch 15/20: 100%
500/500 [12:06<00:00, 1.34s/batch, avg_loss=1.58, acc=68.8, avg_acc=69.7]
[[550 108  30   8  41  27 229   7]
 [ 79 183  99  77 274  55 132 101]
 [  5 154 622  18  49  16  11 125]
 [  3 266  44 540  87  16  18  26]
 [  4  33  82  28 625  10  80 138]
 [ 37  93  92  27 142 481  54  74]
 [ 97  68   6   6 125  44 540 114]
 [  2 171 120  48 205  16  34 404]]
Epoch [15/20],Train Loss: 1.5759. Train Accuracy: 69.6703125 Val Loss: 1.775990026548505 Val Accuracy: tensor([49.3125])
Epoch 16/20: 100%
500/500 [10:59<00:00, 1.21s/batch, avg_loss=1.57, acc=71.9, avg_acc=70.5]
[[557  77  35  10  28  61 228   4]
 [ 78 140  97 107 202  87 182 107]
 [  4 102 608  18  47  32  23 166]
 [  2 220  30 578  66  35  38  31]
 [  6  24  59  36 573  12 105 185]
 [ 26  46  99  26 145 509  73  76]
 [ 68  50   6   5 101  54 618  98]
 [  2 148  90  52 164  21  89 434]]
Epoch [16/20],Train Loss: 1.5689. Train Accuracy: 70.475 Val Loss: 1.7663674155324698 Val Accuracy: tensor([50.2125])
Epoch 17/20: 100%
500/500 [11:02<00:00, 1.26s/batch, avg_loss=1.56, acc=70.3, avg_acc=71.1]
[[470 101  26  10  22 120 248   3]
 [ 51 221  85 115 149 136 166  77]
 [  1 200 550  31  30  71  14 103]
 [  4 344  31 488  38  47  26  22]
 [  4  64  82  64 530  44  86 126]
 [ 10  77  47  18 131 609  53  55]
 [ 63  55   4   5  89  85 591 108]
 [  0 251 111  71 161  40  73 293]]
Epoch [17/20],Train Loss: 1.5619. Train Accuracy: 71.0921875 Val Loss: 1.7995986492037772 Val Accuracy: tensor([46.9000])
Epoch 18/20: 100%
500/500 [11:35<00:00, 1.41s/batch, avg_loss=1.56, acc=66.4, avg_acc=71.8]
[[631  63  28  19  40  32 186   1]
 [ 90 115  85 174 245  71 148  72]
 [  6 135 580  77  48  59   8  87]
 [  6  72  30 761  69  24  18  20]
 [  4  21 106  72 594  28  73 102]
 [ 33  63  61  36 198 502  60  47]
 [119  63   7  13 112  33 549 104]
 [  2 133 121 137 318  27  40 222]]
Epoch [18/20],Train Loss: 1.5552. Train Accuracy: 71.8296875 Val Loss: 1.7755374587029218 Val Accuracy: tensor([49.4250])








NNET1 + BN 

dataset: fma_small_stft_transposed_22050_overlapped (normalized)
batch_size=128, num_epochs=20, learning_rate=0.001, Adam(weight_decay=1e-5)

Epoch 1/20: 100%
1000/1000 [20:33<00:00, 1.01s/batch, avg_loss=1.78, acc=53.9, avg_acc=49.1]
[[1254  144   45   11   80   64  402    0]
 [ 233  259  249  184  633  117  290   35]
 [  65  248 1321   78  144   81   14   49]
 [  19  546   85  982  259   50   29   30]
 [   9   62  243  121 1361   41  106   57]
 [ 114  102  227   42  363 1045   75   32]
 [ 280   64   36   38  381   76 1016  109]
 [  11  271  303  165  805   71  177  197]]
Epoch [1/20],Train Loss: 1.7810. Train Accuracy: 49.09296875 Val Loss: 1.804537734977901 Val Accuracy: tensor([46.4688])
Epoch 2/20: 100%
1000/1000 [19:51<00:00, 1.09s/batch, avg_loss=1.7, acc=49.2, avg_acc=57.4]
[[1257   84   59   22   80  156  336    6]
 [ 136  236  195  214  515  205  286  213]
 [  18  239 1047   88   69  142   11  386]
 [  18  183   44 1356  205   62   46   86]
 [  14   17  129   99 1204   40  139  358]
 [  48   60  135   62  356 1094   59  186]
 [ 207   65   21   20  218  170 1077  222]
 [   0  175  141  142  531   81  174  756]]
Epoch [2/20],Train Loss: 1.6973. Train Accuracy: 57.4046875 Val Loss: 1.7674435658752918 Val Accuracy: tensor([50.1688])
Epoch 3/20: 100%
1000/1000 [20:43<00:00, 1.07s/batch, avg_loss=1.66, acc=64.1, avg_acc=61]
[[1181   86   58   13   48  115  493    6]
 [ 137  285  219  248  355  152  407  197]
 [   8  299 1107   68   44   38   10  426]
 [   2  411   70 1199  161   35   53   69]
 [  18   73  130  108 1066   25  232  348]
 [  34   65  188   58  267 1064  106  218]
 [ 220  135   21   28  196   74 1165  161]
 [   3  280  194  140  342   81  147  813]]
Epoch [3/20],Train Loss: 1.6623. Train Accuracy: 60.9796875 Val Loss: 1.7760336170494557 Val Accuracy: tensor([49.2500])
Epoch 4/20: 100%
1000/1000 [20:19<00:00, 1.04s/batch, avg_loss=1.64, acc=62.5, avg_acc=63.2]
[[1125  136   31   15   80  179  427    7]
 [ 172  219  117  248  662  135  368   79]
 [  58  246  713  172  552  156    7   96]
 [   7  411   49 1166  231   48   53   35]
 [  13   33   76  129 1501   25  168   55]
 [  25   88   91   46  498 1057  101   94]
 [ 175   68    9   50  321  109 1199   69]
 [   0  222  115  157  733   75  195  503]]
Epoch [4/20],Train Loss: 1.6395. Train Accuracy: 63.21171875 Val Loss: 1.801216781206429 Val Accuracy: tensor([46.7687])
Epoch 5/20: 100%
1000/1000 [21:08<00:00, 1.09s/batch, avg_loss=1.62, acc=58.6, avg_acc=65]
[[ 861  220   27   11   75  168  635    3]
 [ 102  319  308  169  467  201  337   97]
 [  15  298 1348   55   19  108   13  144]
 [  10  410   84 1072  249   98   38   39]
 [   3   42  316   78 1108   88  139  226]
 [  19  108  319   23   88 1135  110  198]
 [ 135  104   52   29  221  181 1112  166]
 [   1  380  344  101  481   87  156  450]]
Epoch [5/20],Train Loss: 1.6215. Train Accuracy: 65.015625 Val Loss: 1.8067267959192395 Val Accuracy: tensor([46.2812])
Epoch 6/20: 100%
1000/1000 [19:44<00:00, 1.11s/batch, avg_loss=1.6, acc=70.3, avg_acc=66.7]
[[ 933  174   32    8   62  218  572    1]
 [ 124  251  221  197  451  212  419  125]
 [  26  352 1128   53   51  190   26  174]
 [  13  385   63 1164  163   98   58   56]
 [   5   61  239   84 1211   67  181  152]
 [  22   96  127   23  298 1160  144  130]
 [ 190  106   11   13  255  133 1113  179]
 [   1  349  258  118  375   86  274  539]]
Epoch [6/20],Train Loss: 1.6047. Train Accuracy: 66.74375 Val Loss: 1.7990288497433067 Val Accuracy: tensor([46.8688])
Epoch 7/20: 100%
1000/1000 [20:34<00:00, 1.06s/batch, avg_loss=1.59, acc=65.6, avg_acc=68.3]
[[ 920  328   29   10   60  115  534    4]
 [ 100  413  117  214  480  100  472  104]
 [   3  464  862   64  230   73   50  254]
 [   3  750   43  975   94   28   57   50]
 [   2   96   89  136 1293   26  210  148]
 [  16  167  120   41  395  963  191  107]
 [ 151   89    8   29  225   75 1290  133]
 [   1  403   77  125  559   91  274  470]]
Epoch [7/20],Train Loss: 1.5900. Train Accuracy: 68.25703125 Val Loss: 1.8196136445552111 Val Accuracy: tensor([44.9125])
Epoch 8/20: 100%
1000/1000 [20:03<00:00, 1.24s/batch, avg_loss=1.58, acc=68, avg_acc=69.4]
[[1032  189   30    9   36  170  521   13]
 [ 103  279  168  204  368  192  408  278]
 [   8  230 1055   57   97  189    8  356]
 [   2  435   59 1120  155   75   54  100]
 [   5   65  166   72 1098   64  251  279]
 [  20   95  113   29  240 1144  145  214]
 [ 189  117   12   16  163   95 1200  208]
 [   4  227  204   75  369  109  176  836]]
Epoch [8/20],Train Loss: 1.5784. Train Accuracy: 69.4 Val Loss: 1.7832117640972138 Val Accuracy: tensor([48.5250])
Epoch 9/20: 100%
1000/1000 [21:17<00:00, 1.14s/batch, avg_loss=1.57, acc=68, avg_acc=70.5]
[[ 982  439   36   13   58  121  348    3]
 [ 153  496  203  212  350  167  247  172]
 [  10  416 1029   75   34  180   13  243]
 [   8  729   54  971  100   64   32   42]
 [  14  120  184  139 1111   67  121  244]
 [  15  206  179   33  212 1138   88  129]
 [ 211  216   10   37  203  110 1012  201]
 [   1  567  223  106  312   90   88  613]]
Epoch [9/20],Train Loss: 1.5673. Train Accuracy: 70.54296875 Val Loss: 1.8086598437204957 Val Accuracy: tensor([45.9500])
Epoch 10/20: 100%
1000/1000 [21:13<00:00, 1.38s/batch, avg_loss=1.56, acc=75.8, avg_acc=71.3]
[[ 901  419   23   17   61  114  446   19]
 [ 110  402  149  224  367  134  330  284]
 [  10  458 1031   33   86   82   36  264]
 [   5  460   43 1189  131   58   42   72]
 [   5  117  161  120 1119   41  168  269]
 [  19  202  136   28  194 1096  146  179]
 [ 116  206    5   21  185   34 1197  236]
 [   0  358  144   62  427   91  248  670]]
Epoch [10/20],Train Loss: 1.5589. Train Accuracy: 71.34453125 Val Loss: 1.7932688214182855 Val Accuracy: tensor([47.5312])
Epoch 11/20: 100%
1000/1000 [20:30<00:00, 1.13s/batch, avg_loss=1.55, acc=70.3, avg_acc=72.3]
[[1035  327   27   32   31  226  315    7]
 [ 154  410  191  255  358  182  279  171]
 [   9  354 1184   65   43   93   28  224]
 [   3  411   49 1311   89   46   49   42]
 [  11  107  194  119 1139   64  149  217]
 [  21   97  210   40  201 1234  100   97]
 [ 265  197   11   22  197  159  957  192]
 [   1  349  174  124  317  108  379  548]]
Epoch [11/20],Train Loss: 1.5493. Train Accuracy: 72.34296875 Val Loss: 1.7800576354265214 Val Accuracy: tensor([48.8625])




