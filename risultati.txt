nnet1:
--------------------------------------------
Epoch 1/10: 100%
125/125 [08:20<00:00, 4.20s/batch, avg_loss=1.93, acc=37.1, avg_acc=33.4]
Epoch [1/10], Loss: 1.9256. Accuracy: 33.390625
Epoch 2/10: 100%
125/125 [08:23<00:00, 4.10s/batch, avg_loss=1.86, acc=40.8, avg_acc=40]
Epoch [2/10], Loss: 1.8649. Accuracy: 40.003125
Epoch 3/10: 100%
125/125 [08:02<00:00, 4.18s/batch, avg_loss=1.83, acc=46.1, avg_acc=44]
Epoch [3/10], Loss: 1.8268. Accuracy: 43.959375
Epoch 4/10: 100%
125/125 [08:22<00:00, 5.18s/batch, avg_loss=1.8, acc=46.5, avg_acc=46.4]
Epoch [4/10], Loss: 1.8039. Accuracy: 46.3859375
Epoch 5/10: 100%
125/125 [07:47<00:00, 4.04s/batch, avg_loss=1.78, acc=52.3, avg_acc=48.6]
Epoch [5/10], Loss: 1.7823. Accuracy: 48.634375
Epoch 6/10: 100%
125/125 [08:11<00:00, 4.33s/batch, avg_loss=1.76, acc=52.7, avg_acc=50.6]
Epoch [6/10], Loss: 1.7642. Accuracy: 50.6125
Epoch 7/10: 100%
125/125 [08:24<00:00, 4.22s/batch, avg_loss=1.75, acc=46.7, avg_acc=51.5]
Epoch [7/10], Loss: 1.7547. Accuracy: 51.4796875
Epoch 8/10: 100%
125/125 [08:55<00:00, 5.20s/batch, avg_loss=1.75, acc=49, avg_acc=52]
Epoch [8/10], Loss: 1.7504. Accuracy: 51.9859375
Epoch 9/10: 100%
125/125 [09:18<00:00, 4.32s/batch, avg_loss=1.73, acc=53.1, avg_acc=53.8]
Epoch [9/10], Loss: 1.7321. Accuracy: 53.7625
Epoch 10/10: 100%
125/125 [08:40<00:00, 4.57s/batch, avg_loss=1.72, acc=52, avg_acc=55]
Epoch [10/10], Loss: 1.7209. Accuracy: 55.0125

FROM NOW EPOCHS STARTS FROM 11:
Epoch 1/50: 100%
125/125 [09:37<00:00, 4.61s/batch, avg_loss=1.71, acc=57.2, avg_acc=56]
Epoch [1/50], Loss: 1.7101. Accuracy: 56.0046875
Epoch 2/50: 100%
125/125 [10:09<00:00, 4.43s/batch, avg_loss=1.7, acc=53.3, avg_acc=56.7]
Epoch [2/50], Loss: 1.7038. Accuracy: 56.7125
Epoch 3/50: 100%
125/125 [08:46<00:00, 4.52s/batch, avg_loss=1.7, acc=63.9, avg_acc=57.4]
Epoch [3/50], Loss: 1.6970. Accuracy: 57.4390625
Epoch 4/50: 100%
125/125 [09:47<00:00, 5.08s/batch, avg_loss=1.7, acc=55.5, avg_acc=57.3]
Epoch [4/50], Loss: 1.6977. Accuracy: 57.2828125
Epoch 5/50: 100%
125/125 [10:45<00:00, 5.79s/batch, avg_loss=1.71, acc=55.1, avg_acc=56.4]
Epoch [5/50], Loss: 1.7067. Accuracy: 56.44375
Epoch 6/50: 100%
125/125 [09:40<00:00, 4.77s/batch, avg_loss=1.69, acc=60.5, avg_acc=58.4]
Epoch [6/50], Loss: 1.6878. Accuracy: 58.378125
Epoch 7/50: 100%
125/125 [08:58<00:00, 4.53s/batch, avg_loss=1.69, acc=53.7, avg_acc=57.7]
Epoch [7/50], Loss: 1.6939. Accuracy: 57.7375
Epoch 8/50: 100%
125/125 [09:01<00:00, 4.32s/batch, avg_loss=1.69, acc=57.8, avg_acc=58.6]
Epoch [8/50], Loss: 1.6853. Accuracy: 58.6171875
Epoch 9/50: 100%
125/125 [08:57<00:00, 4.54s/batch, avg_loss=1.68, acc=60.7, avg_acc=59]
Epoch [9/50], Loss: 1.6810. Accuracy: 59.0296875
Epoch 10/50: 100%
125/125 [09:08<00:00, 4.50s/batch, avg_loss=1.68, acc=58.8, avg_acc=59.2]
Epoch [10/50], Loss: 1.6789. Accuracy: 59.25
Epoch 11/50: 100%
125/125 [09:43<00:00, 5.01s/batch, avg_loss=1.69, acc=60.2, avg_acc=58.5]
Epoch [11/50], Loss: 1.6865. Accuracy: 58.5265625
Epoch 12/50: 100%
125/125 [09:53<00:00, 4.70s/batch, avg_loss=1.67, acc=65, avg_acc=60.4]
Epoch [12/50], Loss: 1.6680. Accuracy: 60.3984375
Epoch 13/50: 100%
125/125 [10:23<00:00, 5.89s/batch, avg_loss=1.67, acc=57.4, avg_acc=60.6]
Epoch [13/50], Loss: 1.6663. Accuracy: 60.59375
Epoch 14/50: 100%
125/125 [09:31<00:00, 4.95s/batch, avg_loss=1.66, acc=60.4, avg_acc=61.1]
EARLY STOPPED

---------------------------------------------
GRID SEARCH lr=[0.01, 0.001, 0.0001], batch_size = [128, 256, 512] EPOCHS = 10


Traing model with batch size=128, lr=0.01
Epoch 1/10: 100%
500/500 [10:11<00:00, 1.54s/batch, avg_loss=2.15, acc=17.2, avg_acc=12.5]
Epoch [1/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 2/10: 100%
500/500 [09:00<00:00, 1.07batch/s, avg_loss=2.15, acc=17.2, avg_acc=12.5]
Epoch [2/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 3/10: 100%
500/500 [09:20<00:00, 1.03batch/s, avg_loss=2.15, acc=13.3, avg_acc=12.5]
Epoch [3/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 4/10: 100%
500/500 [08:55<00:00, 1.00s/batch, avg_loss=2.15, acc=10.9, avg_acc=12.5]
Epoch [4/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 5/10: 100%
500/500 [08:41<00:00, 1.04batch/s, avg_loss=2.15, acc=15.6, avg_acc=12.5]
Epoch [5/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 6/10: 100%
500/500 [08:39<00:00, 1.05batch/s, avg_loss=2.15, acc=6.25, avg_acc=12.5]
Epoch [6/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 7/10: 100%
500/500 [08:40<00:00, 1.02batch/s, avg_loss=2.15, acc=18, avg_acc=12.5]
Epoch [7/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 8/10: 100%
500/500 [08:43<00:00, 1.06batch/s, avg_loss=2.15, acc=15.6, avg_acc=12.5]
Epoch [8/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 9/10: 100%
500/500 [08:48<00:00, 1.05s/batch, avg_loss=2.15, acc=13.3, avg_acc=12.5]
Epoch [9/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 10/10: 100%
500/500 [08:43<00:00, 1.03s/batch, avg_loss=2.15, acc=14.1, avg_acc=12.5]
Epoch [10/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
saving model in models/model_lr_0-01_bs_128
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]]]
Traing model with batch size=256, lr=0.01
Epoch 1/10: 100%
250/250 [08:36<00:00, 1.92s/batch, avg_loss=2.15, acc=13.3, avg_acc=12.5]
Epoch [1/10],Train Loss: 2.1484. Train Accuracy: 12.528125 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 2/10: 100%
250/250 [08:31<00:00, 1.96s/batch, avg_loss=2.15, acc=13.7, avg_acc=12.5]
Epoch [2/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 3/10: 100%
250/250 [08:35<00:00, 1.99s/batch, avg_loss=2.15, acc=8.98, avg_acc=12.5]
Epoch [3/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 4/10: 100%
250/250 [08:28<00:00, 2.02s/batch, avg_loss=2.15, acc=11.7, avg_acc=12.5]
Epoch [4/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 5/10: 100%
250/250 [08:30<00:00, 1.87s/batch, avg_loss=2.15, acc=10.5, avg_acc=12.5]
Epoch [5/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 6/10: 100%
250/250 [08:31<00:00, 1.92s/batch, avg_loss=2.15, acc=11.7, avg_acc=12.5]
Epoch [6/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 7/10: 100%
250/250 [08:30<00:00, 1.98s/batch, avg_loss=2.15, acc=14.1, avg_acc=12.5]
Epoch [7/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 8/10: 100%
250/250 [08:30<00:00, 1.90s/batch, avg_loss=2.15, acc=14.1, avg_acc=12.5]
Epoch [8/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 9/10: 100%
250/250 [08:26<00:00, 1.95s/batch, avg_loss=2.15, acc=10.9, avg_acc=12.5]
Epoch [9/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 10/10: 100%
250/250 [08:32<00:00, 1.97s/batch, avg_loss=2.15, acc=9.77, avg_acc=12.5]
Epoch [10/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
saving model in models/model_lr_0-01_bs_256
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]]]
Traing model with batch size=512, lr=0.01
Epoch 1/10: 100%
125/125 [08:44<00:00, 4.49s/batch, avg_loss=2.15, acc=14.3, avg_acc=12.4]
Epoch [1/10],Train Loss: 2.1485. Train Accuracy: 12.44375 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 2/10: 100%
125/125 [08:29<00:00, 3.91s/batch, avg_loss=2.15, acc=10.9, avg_acc=12.5]
Epoch [2/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 3/10: 100%
125/125 [08:33<00:00, 3.87s/batch, avg_loss=2.15, acc=10.7, avg_acc=12.5]
Epoch [3/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 4/10: 100%
125/125 [08:32<00:00, 3.87s/batch, avg_loss=2.15, acc=13.1, avg_acc=12.5]
Epoch [4/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 5/10: 100%
125/125 [08:36<00:00, 3.92s/batch, avg_loss=2.15, acc=13.3, avg_acc=12.5]
Epoch [5/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 6/10: 100%
125/125 [08:33<00:00, 3.84s/batch, avg_loss=2.15, acc=12.9, avg_acc=12.5]
Epoch [6/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 7/10: 100%
125/125 [08:32<00:00, 3.87s/batch, avg_loss=2.15, acc=12.3, avg_acc=12.5]
Epoch [7/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 8/10: 100%
125/125 [08:34<00:00, 3.91s/batch, avg_loss=2.15, acc=10.9, avg_acc=12.5]
Epoch [8/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 9/10: 100%
125/125 [08:38<00:00, 3.98s/batch, avg_loss=2.15, acc=13.3, avg_acc=12.5]
Epoch [9/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
Epoch 10/10: 100%
125/125 [08:59<00:00, 3.92s/batch, avg_loss=2.15, acc=15.8, avg_acc=12.5]
Epoch [10/10],Train Loss: 2.1490. Train Accuracy: 12.5 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
saving model in models/model_lr_0-01_bs_512
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]]]
Traing model with batch size=128, lr=0.001
Epoch 1/10: 100%
500/500 [09:12<00:00, 1.17s/batch, avg_loss=1.93, acc=32, avg_acc=32.9]
Epoch [1/10],Train Loss: 1.9344. Train Accuracy: 32.859375 Val Loss: 1.9122745493501425 Val Accuracy: 0.35275
Epoch 2/10: 100%
500/500 [09:24<00:00, 1.21s/batch, avg_loss=1.9, acc=31.2, avg_acc=36.3]
Epoch [2/10],Train Loss: 1.9036. Train Accuracy: 36.2671875 Val Loss: 1.9172266080379485 Val Accuracy: 0.353
Epoch 3/10: 100%
500/500 [09:33<00:00, 1.04s/batch, avg_loss=1.89, acc=38.3, avg_acc=37.9]
Epoch [3/10],Train Loss: 1.8897. Train Accuracy: 37.884375 Val Loss: 1.914251158580184 Val Accuracy: 0.35525
Epoch 4/10: 100%
500/500 [09:31<00:00, 1.16s/batch, avg_loss=1.87, acc=43.8, avg_acc=39.7]
Epoch [4/10],Train Loss: 1.8700. Train Accuracy: 39.7453125 Val Loss: 1.8817764599770308 Val Accuracy: 0.387375
Epoch 5/10: 100%
500/500 [09:45<00:00, 1.12s/batch, avg_loss=1.89, acc=39.1, avg_acc=37.9]
Epoch [5/10],Train Loss: 1.8914. Train Accuracy: 37.86875 Val Loss: 1.9169727702736854 Val Accuracy: 0.354
Epoch 6/10: 100%
500/500 [09:33<00:00, 1.03s/batch, avg_loss=1.99, acc=28.1, avg_acc=28.5]
Epoch [6/10],Train Loss: 1.9876. Train Accuracy: 28.528125 Val Loss: 1.996893467321992 Val Accuracy: 0.276875
Epoch 7/10: 100%
500/500 [09:25<00:00, 1.01batch/s, avg_loss=2.09, acc=18.8, avg_acc=18.3]
Epoch [7/10],Train Loss: 2.0914. Train Accuracy: 18.2515625 Val Loss: 2.07832046996057 Val Accuracy: 0.195625
Epoch 8/10: 100%
500/500 [08:45<00:00, 1.02s/batch, avg_loss=2.08, acc=24.2, avg_acc=19.6]
Epoch [8/10],Train Loss: 2.0782. Train Accuracy: 19.5765625 Val Loss: 2.060501457422972 Val Accuracy: 0.2135
Epoch 9/10: 100%
500/500 [08:40<00:00, 1.02s/batch, avg_loss=2.12, acc=13.3, avg_acc=15.8]
Epoch [9/10],Train Loss: 2.1157. Train Accuracy: 15.83125 Val Loss: 2.1483837509155275 Val Accuracy: 0.125625
Epoch 10/10: 100%
500/500 [08:41<00:00, 1.02batch/s, avg_loss=2.15, acc=15.6, avg_acc=12.5]
Epoch [10/10],Train Loss: 2.1490. Train Accuracy: 12.5015625 Val Loss: 2.1490087509155273 Val Accuracy: 0.125
saving model in models/model_lr_0-001_bs_128
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]]]
Traing model with batch size=256, lr=0.001
Epoch 1/10: 100%
250/250 [08:44<00:00, 2.11s/batch, avg_loss=1.91, acc=40.6, avg_acc=35.1]
Epoch [1/10],Train Loss: 1.9106. Train Accuracy: 35.0859375 Val Loss: 1.896410737067461 Val Accuracy: 0.3675
Epoch 2/10: 100%
250/250 [09:01<00:00, 2.09s/batch, avg_loss=1.86, acc=43, avg_acc=40.4]
Epoch [2/10],Train Loss: 1.8616. Train Accuracy: 40.4421875 Val Loss: 1.8522914710491896 Val Accuracy: 0.412375
Epoch 3/10: 100%
250/250 [09:09<00:00, 2.21s/batch, avg_loss=1.84, acc=47.7, avg_acc=42.8]
Epoch [3/10],Train Loss: 1.8395. Train Accuracy: 42.84375 Val Loss: 1.8260197767913342 Val Accuracy: 0.439375
Epoch 4/10: 100%
250/250 [09:18<00:00, 2.25s/batch, avg_loss=1.82, acc=53.1, avg_acc=45.2]
Epoch [4/10],Train Loss: 1.8156. Train Accuracy: 45.21875 Val Loss: 1.8525366085767745 Val Accuracy: 0.4135
Epoch 5/10: 100%
250/250 [09:20<00:00, 2.07s/batch, avg_loss=1.8, acc=48, avg_acc=47.3]
Epoch [5/10],Train Loss: 1.7958. Train Accuracy: 47.28125 Val Loss: 1.8349460310041905 Val Accuracy: 0.433125
Epoch 6/10: 100%
250/250 [09:28<00:00, 2.20s/batch, avg_loss=1.8, acc=51.6, avg_acc=47.4]
Epoch [6/10],Train Loss: 1.7959. Train Accuracy: 47.403125 Val Loss: 1.8046241473853588 Val Accuracy: 0.465375
Epoch 7/10: 100%
250/250 [09:37<00:00, 2.12s/batch, avg_loss=1.79, acc=51.2, avg_acc=47.9]
Epoch [7/10],Train Loss: 1.7912. Train Accuracy: 47.8765625 Val Loss: 1.8275287748426199 Val Accuracy: 0.440875
Epoch 8/10: 100%
250/250 [09:43<00:00, 2.24s/batch, avg_loss=1.79, acc=53.1, avg_acc=48.1]
Epoch [8/10],Train Loss: 1.7880. Train Accuracy: 48.10625 Val Loss: 1.8104271434694528 Val Accuracy: 0.4605
Epoch 9/10: 100%
250/250 [09:43<00:00, 2.13s/batch, avg_loss=1.77, acc=51.6, avg_acc=50.5]
Epoch [9/10],Train Loss: 1.7655. Train Accuracy: 50.4625 Val Loss: 1.8292202703207732 Val Accuracy: 0.4445
Epoch 10/10: 100%
250/250 [09:57<00:00, 2.35s/batch, avg_loss=1.77, acc=43.4, avg_acc=50.4]
Epoch [10/10],Train Loss: 1.7659. Train Accuracy: 50.4140625 Val Loss: 1.8237933877855539 Val Accuracy: 0.447125
saving model in models/model_lr_0-001_bs_256
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]], [[0.3675, 0.412375, 0.439375, 0.4135, 0.433125, 0.465375, 0.440875, 0.4605, 0.4445, 0.447125], [1.896410737067461, 1.8522914710491896, 1.8260197767913342, 1.8525366085767745, 1.8349460310041905, 1.8046241473853588, 1.8275287748426199, 1.8104271434694528, 1.8292202703207732, 1.8237933877855539]]]
Traing model with batch size=512, lr=0.001
Epoch 1/10: 100%
125/125 [08:44<00:00, 4.10s/batch, avg_loss=1.91, acc=39.5, avg_acc=34.6]
Epoch [1/10],Train Loss: 1.9143. Train Accuracy: 34.6125 Val Loss: 1.882827129766345 Val Accuracy: 0.376375
Epoch 2/10: 100%
125/125 [08:47<00:00, 4.00s/batch, avg_loss=1.86, acc=43.2, avg_acc=40.7]
Epoch [2/10],Train Loss: 1.8583. Train Accuracy: 40.7390625 Val Loss: 1.8444042218923569 Val Accuracy: 0.42575
Epoch 3/10: 100%
125/125 [08:52<00:00, 4.23s/batch, avg_loss=1.83, acc=42, avg_acc=44]
Epoch [3/10],Train Loss: 1.8276. Train Accuracy: 43.9921875 Val Loss: 1.8413038718253374 Val Accuracy: 0.428875
Epoch 4/10: 100%
125/125 [09:00<00:00, 4.18s/batch, avg_loss=1.82, acc=46.1, avg_acc=45.1]
Epoch [4/10],Train Loss: 1.8172. Train Accuracy: 45.0578125 Val Loss: 1.8464463885724545 Val Accuracy: 0.42025
Epoch 5/10: 100%
125/125 [09:11<00:00, 4.32s/batch, avg_loss=1.8, acc=43.8, avg_acc=47]
Epoch [5/10],Train Loss: 1.7989. Train Accuracy: 46.990625 Val Loss: 1.8387476181536913 Val Accuracy: 0.428
Epoch 6/10: 100%
125/125 [09:07<00:00, 4.21s/batch, avg_loss=1.78, acc=52, avg_acc=49.1]
Epoch [6/10],Train Loss: 1.7782. Train Accuracy: 49.08125 Val Loss: 1.8239915691167117 Val Accuracy: 0.4415
Epoch 7/10: 100%
125/125 [09:03<00:00, 4.19s/batch, avg_loss=1.75, acc=50.6, avg_acc=51.6]
Epoch [7/10],Train Loss: 1.7536. Train Accuracy: 51.5921875 Val Loss: 1.8128462145626545 Val Accuracy: 0.455125
Epoch 8/10: 100%
125/125 [09:40<00:00, 4.23s/batch, avg_loss=1.75, acc=50.8, avg_acc=52.4]
Epoch [8/10],Train Loss: 1.7462. Train Accuracy: 52.3625 Val Loss: 1.8042407598495482 Val Accuracy: 0.46675
Epoch 9/10: 100%
125/125 [09:07<00:00, 4.14s/batch, avg_loss=1.74, acc=54.1, avg_acc=53.4]
Epoch [9/10],Train Loss: 1.7367. Train Accuracy: 53.3984375 Val Loss: 1.7893701848238706 Val Accuracy: 0.48225
Epoch 10/10: 100%
125/125 [09:28<00:00, 4.34s/batch, avg_loss=1.74, acc=55.9, avg_acc=53.5]
Epoch [10/10],Train Loss: 1.7353. Train Accuracy: 53.521875 Val Loss: 1.7999915072023869 Val Accuracy: 0.470375
saving model in models/model_lr_0-001_bs_512
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]], [[0.3675, 0.412375, 0.439375, 0.4135, 0.433125, 0.465375, 0.440875, 0.4605, 0.4445, 0.447125], [1.896410737067461, 1.8522914710491896, 1.8260197767913342, 1.8525366085767745, 1.8349460310041905, 1.8046241473853588, 1.8275287748426199, 1.8104271434694528, 1.8292202703207732, 1.8237933877855539]], [[0.376375, 0.42575, 0.428875, 0.42025, 0.428, 0.4415, 0.455125, 0.46675, 0.48225, 0.470375], [1.882827129766345, 1.8444042218923569, 1.8413038718253374, 1.8464463885724545, 1.8387476181536913, 1.8239915691167117, 1.8128462145626545, 1.8042407598495482, 1.7893701848238706, 1.7999915072023869]]]
Traing model with batch size=128, lr=0.0001
Epoch 1/10: 100%
500/500 [08:57<00:00, 1.07s/batch, avg_loss=1.92, acc=32.8, avg_acc=35.2]
Epoch [1/10],Train Loss: 1.9151. Train Accuracy: 35.1765625 Val Loss: 1.8935416251718997 Val Accuracy: 0.371375
Epoch 2/10: 100%
500/500 [08:50<00:00, 1.04s/batch, avg_loss=1.86, acc=40.6, avg_acc=41.1]
Epoch [2/10],Train Loss: 1.8556. Train Accuracy: 41.1390625 Val Loss: 1.8745876116603613 Val Accuracy: 0.384375
Epoch 3/10: 100%
500/500 [08:50<00:00, 1.05s/batch, avg_loss=1.83, acc=54.7, avg_acc=44]
Epoch [3/10],Train Loss: 1.8275. Train Accuracy: 44.0453125 Val Loss: 1.8485859577804804 Val Accuracy: 0.412625
Epoch 4/10: 100%
500/500 [08:49<00:00, 1.08s/batch, avg_loss=1.8, acc=48.4, avg_acc=47.2]
Epoch [4/10],Train Loss: 1.7984. Train Accuracy: 47.203125 Val Loss: 1.849452141225338 Val Accuracy: 0.41175
Epoch 5/10: 100%
500/500 [08:51<00:00, 1.00batch/s, avg_loss=1.78, acc=43, avg_acc=49.4]
Epoch [5/10],Train Loss: 1.7769. Train Accuracy: 49.3703125 Val Loss: 1.8201128201037646 Val Accuracy: 0.44825
Epoch 6/10: 100%
500/500 [09:08<00:00, 1.00s/batch, avg_loss=1.76, acc=53.9, avg_acc=51.5]
Epoch [6/10],Train Loss: 1.7571. Train Accuracy: 51.55 Val Loss: 1.8425580082833768 Val Accuracy: 0.428875
Epoch 7/10: 100%
500/500 [08:49<00:00, 1.02s/batch, avg_loss=1.74, acc=45.3, avg_acc=52.8]
Epoch [7/10],Train Loss: 1.7429. Train Accuracy: 52.8484375 Val Loss: 1.808242661178112 Val Accuracy: 0.459625
Epoch 8/10: 100%
500/500 [09:17<00:00, 1.03batch/s, avg_loss=1.73, acc=48.4, avg_acc=54.2]
Epoch [8/10],Train Loss: 1.7301. Train Accuracy: 54.2140625 Val Loss: 1.8058343342989682 Val Accuracy: 0.4645
Epoch 9/10: 100%
500/500 [08:58<00:00, 1.02batch/s, avg_loss=1.72, acc=60.2, avg_acc=55.5]
Epoch [9/10],Train Loss: 1.7184. Train Accuracy: 55.5015625 Val Loss: 1.806230291634798 Val Accuracy: 0.473625
Epoch 10/10: 100%
500/500 [08:49<00:00, 1.01batch/s, avg_loss=1.71, acc=55.5, avg_acc=56.7]
Epoch [10/10],Train Loss: 1.7064. Train Accuracy: 56.6515625 Val Loss: 1.8007425208240748 Val Accuracy: 0.473125
saving model in models/model_lr_0-0001_bs_128
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]], [[0.3675, 0.412375, 0.439375, 0.4135, 0.433125, 0.465375, 0.440875, 0.4605, 0.4445, 0.447125], [1.896410737067461, 1.8522914710491896, 1.8260197767913342, 1.8525366085767745, 1.8349460310041905, 1.8046241473853588, 1.8275287748426199, 1.8104271434694528, 1.8292202703207732, 1.8237933877855539]], [[0.376375, 0.42575, 0.428875, 0.42025, 0.428, 0.4415, 0.455125, 0.46675, 0.48225, 0.470375], [1.882827129766345, 1.8444042218923569, 1.8413038718253374, 1.8464463885724545, 1.8387476181536913, 1.8239915691167117, 1.8128462145626545, 1.8042407598495482, 1.7893701848238706, 1.7999915072023869]], [[0.371375, 0.384375, 0.412625, 0.41175, 0.44825, 0.428875, 0.459625, 0.4645, 0.473625, 0.473125], [1.8935416251718997, 1.8745876116603613, 1.8485859577804804, 1.849452141225338, 1.8201128201037646, 1.8425580082833768, 1.808242661178112, 1.8058343342989682, 1.806230291634798, 1.8007425208240748]]]
Traing model with batch size=256, lr=0.0001
Epoch 1/10: 100%
250/250 [09:34<00:00, 2.12s/batch, avg_loss=1.93, acc=35.5, avg_acc=32.8]
Epoch [1/10],Train Loss: 1.9325. Train Accuracy: 32.8109375 Val Loss: 1.8994971818625928 Val Accuracy: 0.35675
Epoch 2/10: 100%
250/250 [11:29<00:00, 2.33s/batch, avg_loss=1.87, acc=43.8, avg_acc=39.8]
Epoch [2/10],Train Loss: 1.8675. Train Accuracy: 39.80625 Val Loss: 1.8854113938063384 Val Accuracy: 0.372125
Epoch 3/10: 100%
250/250 [11:04<00:00, 2.38s/batch, avg_loss=1.85, acc=44.9, avg_acc=42.3]
Epoch [3/10],Train Loss: 1.8452. Train Accuracy: 42.2765625 Val Loss: 1.8769579823166131 Val Accuracy: 0.385125
Epoch 4/10: 100%
250/250 [09:24<00:00, 2.00s/batch, avg_loss=1.82, acc=47.7, avg_acc=44.6]
Epoch [4/10],Train Loss: 1.8229. Train Accuracy: 44.5640625 Val Loss: 1.8551166446208953 Val Accuracy: 0.40975
Epoch 5/10: 100%
250/250 [10:21<00:00, 2.34s/batch, avg_loss=1.81, acc=46.5, avg_acc=46.4]
Epoch [5/10],Train Loss: 1.8053. Train Accuracy: 46.4140625 Val Loss: 1.8545966487824916 Val Accuracy: 0.406625
Epoch 6/10: 100%
250/250 [10:17<00:00, 2.62s/batch, avg_loss=1.79, acc=45.7, avg_acc=48.2]
Epoch [6/10],Train Loss: 1.7896. Train Accuracy: 48.209375 Val Loss: 1.8329055020064116 Val Accuracy: 0.428875
Epoch 7/10: 100%
250/250 [09:54<00:00, 2.15s/batch, avg_loss=1.77, acc=52.3, avg_acc=50]
Epoch [7/10],Train Loss: 1.7724. Train Accuracy: 49.9828125 Val Loss: 1.8317571551799774 Val Accuracy: 0.439375
Epoch 8/10: 100%
250/250 [10:42<00:00, 2.53s/batch, avg_loss=1.76, acc=52.3, avg_acc=51.1]
Epoch [8/10],Train Loss: 1.7615. Train Accuracy: 51.0796875 Val Loss: 1.8060852632671596 Val Accuracy: 0.465375
Epoch 9/10: 100%
250/250 [12:08<00:00, 2.92s/batch, avg_loss=1.75, acc=51.6, avg_acc=52.3]
Epoch [9/10],Train Loss: 1.7491. Train Accuracy: 52.3265625 Val Loss: 1.813155138656497 Val Accuracy: 0.4585
Epoch 10/10: 100%
250/250 [20:17<00:00, 3.22s/batch, avg_loss=1.74, acc=57.4, avg_acc=53.4]
Epoch [10/10],Train Loss: 1.7382. Train Accuracy: 53.421875 Val Loss: 1.8029643515199423 Val Accuracy: 0.4685
saving model in models/model_lr_0-0001_bs_256
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]], [[0.3675, 0.412375, 0.439375, 0.4135, 0.433125, 0.465375, 0.440875, 0.4605, 0.4445, 0.447125], [1.896410737067461, 1.8522914710491896, 1.8260197767913342, 1.8525366085767745, 1.8349460310041905, 1.8046241473853588, 1.8275287748426199, 1.8104271434694528, 1.8292202703207732, 1.8237933877855539]], [[0.376375, 0.42575, 0.428875, 0.42025, 0.428, 0.4415, 0.455125, 0.46675, 0.48225, 0.470375], [1.882827129766345, 1.8444042218923569, 1.8413038718253374, 1.8464463885724545, 1.8387476181536913, 1.8239915691167117, 1.8128462145626545, 1.8042407598495482, 1.7893701848238706, 1.7999915072023869]], [[0.371375, 0.384375, 0.412625, 0.41175, 0.44825, 0.428875, 0.459625, 0.4645, 0.473625, 0.473125], [1.8935416251718997, 1.8745876116603613, 1.8485859577804804, 1.849452141225338, 1.8201128201037646, 1.8425580082833768, 1.808242661178112, 1.8058343342989682, 1.806230291634798, 1.8007425208240748]], [[0.35675, 0.372125, 0.385125, 0.40975, 0.406625, 0.428875, 0.439375, 0.465375, 0.4585, 0.4685], [1.8994971818625928, 1.8854113938063384, 1.8769579823166131, 1.8551166446208953, 1.8545966487824916, 1.8329055020064116, 1.8317571551799774, 1.8060852632671596, 1.813155138656497, 1.8029643515199423]]]
Traing model with batch size=512, lr=0.0001
Epoch 1/10: 100%
125/125 [12:11<00:00, 4.79s/batch, avg_loss=1.97, acc=39.1, avg_acc=28.9]
Epoch [1/10],Train Loss: 1.9654. Train Accuracy: 28.95 Val Loss: 1.9048996717184783 Val Accuracy: 0.365125
Epoch 2/10: 100%
125/125 [09:44<00:00, 4.12s/batch, avg_loss=1.88, acc=36.7, avg_acc=39.4]
Epoch [2/10],Train Loss: 1.8758. Train Accuracy: 39.4140625 Val Loss: 1.883847340464592 Val Accuracy: 0.380875
Epoch 3/10: 100%
125/125 [10:30<00:00, 3.98s/batch, avg_loss=1.86, acc=38.5, avg_acc=41.2]
Epoch [3/10],Train Loss: 1.8565. Train Accuracy: 41.2125 Val Loss: 1.8755802492052316 Val Accuracy: 0.3845
Epoch 4/10: 100%
125/125 [08:55<00:00, 4.05s/batch, avg_loss=1.84, acc=43.6, avg_acc=43.1]
Epoch [4/10],Train Loss: 1.8391. Train Accuracy: 43.1046875 Val Loss: 1.8552769204229116 Val Accuracy: 0.405
Epoch 5/10: 100%
125/125 [08:57<00:00, 4.18s/batch, avg_loss=1.82, acc=46.9, avg_acc=45.1]
Epoch [5/10],Train Loss: 1.8202. Train Accuracy: 45.0546875 Val Loss: 1.838795747473836 Val Accuracy: 0.42425
Epoch 6/10: 100%
125/125 [08:55<00:00, 4.02s/batch, avg_loss=1.8, acc=47.3, avg_acc=46.8]
Epoch [6/10],Train Loss: 1.8045. Train Accuracy: 46.80625 Val Loss: 1.8407539522200822 Val Accuracy: 0.424625
Epoch 7/10: 100%
125/125 [09:48<00:00, 4.65s/batch, avg_loss=1.8, acc=49.2, avg_acc=47.6]
Epoch [7/10],Train Loss: 1.7951. Train Accuracy: 47.6171875 Val Loss: 1.826495782598853 Val Accuracy: 0.434375
Epoch 8/10: 100%
125/125 [10:44<00:00, 4.43s/batch, avg_loss=1.79, acc=45.9, avg_acc=48.7]
Epoch [8/10],Train Loss: 1.7855. Train Accuracy: 48.7125 Val Loss: 1.8369564942121506 Val Accuracy: 0.432125
Epoch 9/10: 100%
125/125 [09:40<00:00, 4.38s/batch, avg_loss=1.77, acc=49, avg_acc=50.1]
Epoch [9/10],Train Loss: 1.7722. Train Accuracy: 50.0890625 Val Loss: 1.8237806998342276 Val Accuracy: 0.44325
Epoch 10/10: 100%
125/125 [11:23<00:00, 4.67s/batch, avg_loss=1.76, acc=52.3, avg_acc=50.9]
Epoch [10/10],Train Loss: 1.7646. Train Accuracy: 50.9234375 Val Loss: 1.816964417949319 Val Accuracy: 0.4535
saving model in models/model_lr_0-0001_bs_512
[[[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125], [2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273, 2.1490087509155273]], [[0.35275, 0.353, 0.35525, 0.387375, 0.354, 0.276875, 0.195625, 0.2135, 0.125625, 0.125], [1.9122745493501425, 1.9172266080379485, 1.914251158580184, 1.8817764599770308, 1.9169727702736854, 1.996893467321992, 2.07832046996057, 2.060501457422972, 2.1483837509155275, 2.1490087509155273]], [[0.3675, 0.412375, 0.439375, 0.4135, 0.433125, 0.465375, 0.440875, 0.4605, 0.4445, 0.447125], [1.896410737067461, 1.8522914710491896, 1.8260197767913342, 1.8525366085767745, 1.8349460310041905, 1.8046241473853588, 1.8275287748426199, 1.8104271434694528, 1.8292202703207732, 1.8237933877855539]], [[0.376375, 0.42575, 0.428875, 0.42025, 0.428, 0.4415, 0.455125, 0.46675, 0.48225, 0.470375], [1.882827129766345, 1.8444042218923569, 1.8413038718253374, 1.8464463885724545, 1.8387476181536913, 1.8239915691167117, 1.8128462145626545, 1.8042407598495482, 1.7893701848238706, 1.7999915072023869]], [[0.371375, 0.384375, 0.412625, 0.41175, 0.44825, 0.428875, 0.459625, 0.4645, 0.473625, 0.473125], [1.8935416251718997, 1.8745876116603613, 1.8485859577804804, 1.849452141225338, 1.8201128201037646, 1.8425580082833768, 1.808242661178112, 1.8058343342989682, 1.806230291634798, 1.8007425208240748]], [[0.35675, 0.372125, 0.385125, 0.40975, 0.406625, 0.428875, 0.439375, 0.465375, 0.4585, 0.4685], [1.8994971818625928, 1.8854113938063384, 1.8769579823166131, 1.8551166446208953, 1.8545966487824916, 1.8329055020064116, 1.8317571551799774, 1.8060852632671596, 1.813155138656497, 1.8029643515199423]], [[0.365125, 0.380875, 0.3845, 0.405, 0.42425, 0.424625, 0.434375, 0.432125, 0.44325, 0.4535], [1.9048996717184783, 1.883847340464592, 1.8755802492052316, 1.8552769204229116, 1.838795747473836, 1.8407539522200822, 1.826495782598853, 1.8369564942121506, 1.8237806998342276, 1.816964417949319]]]
 
